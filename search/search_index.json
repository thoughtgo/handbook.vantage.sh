{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Cloud Cost Handbook","text":"<p>The Cloud Cost Handbook is a free, open-source, community-supported set of guides meant to help explain often-times complex pricing of public cloud infrastructure and service providers in easy-to-understand terms. This guide is hosted on Github and is open to anyone to contribute their knowledge to the community. Vantage employees will maintain hosting the guide for everyone and ensure that content is relevant and adheres to styleguides.</p>"},{"location":"#structure","title":"Structure","text":"<p>This handbook is separated into two different sections for the time-being as explained below:</p>"},{"location":"#general-concepts","title":"General Concepts","text":"<p>These are general concepts that don't necessarily map directly to a particular service.</p>"},{"location":"#provider-services","title":"Provider Services","text":"<p>Provider Services are meant to be the source of truth for explaining not only the pricing mechanics of the service but also to explain potentially nuanced concepts related to costs for that service. The focus of these pages is meant to be for the pricing of these services and not related to the actual management or orchestration of the service itself.</p>"},{"location":"#contributing","title":"Contributing","text":"<p>Anyone is welcome to contribute to the Cloud Cost Handbook by issuing a pull request on the GitHub repo. </p> <p> Contribute</p>"},{"location":"#slack-community","title":"Slack Community","text":"<p>Generally interested in cloud concepts and associated costs? Join us in our public Slack community. We have a channel devoted to the handbook named \"cloud-cost-handbook\" where you're welcome to hang out, ask questions and/or spark conversation. </p> <p> Slack Community</p>"},{"location":"aws/concepts/autoscaling/","title":"Autoscaling","text":"<p>The best way to optimize costs in the cloud is to not spend it in the first place. Enter Autoscaling. Autoscaling leverages the elasticity of the cloud to dynamically provision and remove capacity based on demand. That means that as demands decrease autoscaling will automatically scale down resources and allow you to save on costs accordingly. </p> <p>Autoscaling applies to a variety of different services, some of which are described in more detail below. If you're looking for EC2 autoscaling concepts, please see the AWS EC2 service page for the autoscaling section.</p>"},{"location":"aws/concepts/autoscaling/#application-autoscaling","title":"Application Autoscaling","text":"<p>For other resources in AWS, Application Autoscaling provides the ability to adjust provisioned resources.</p> <p>Application Autoscaling supports the following services:</p> <ul> <li>AppStream 2.0 fleets</li> <li>Aurora replicas</li> <li>Amazon Comprehend document classification and entity recognizer endpoints</li> <li>DynamoDB tables and global secondary indexes</li> <li>Amazon Elastic Container Service (ECS) services</li> <li>Amazon EMR clusters</li> <li>Amazon Keyspaces (for Apache Cassandra) tables</li> <li>Lambda function provisioned concurrency</li> <li>Amazon Managed Streaming for Apache Kafka (MSK) broker storage</li> <li>SageMaker endpoint variants</li> </ul>"},{"location":"aws/concepts/autoscaling/#autoscaling-strategies","title":"Autoscaling Strategies","text":"<p>There are various methods by which autoscaling can occur. These are listed below in no partiuclar order:</p> <ul> <li>Target Scaling adds or removes capacity to keep a metric as near a specific value as possible. For example, target average CPU utilization of 50% across a set of ECS Tasks. If CPU utilization gets too high, add nodes. If CPU utilization gets too low, remove nodes.</li> <li>Step Scaling will adjust capacity up and down by dynamic amounts, depending on the magnitude of a metric.</li> <li>Scheduled Scaling will adjust mininmum and maximum capacity settings on a schedule.</li> <li>Simple Scaling will add or remove EC2 instances from an Autoscalng Group when an alarm is in alert state.</li> <li>Predictive Scaling can leverage historical metrics to preemptively scale EC2 workloads based on daily or weekly trends.</li> <li>Manual Scaling is possible with EC2 instances if teams need to intervene with an autoscaling group. This allows you to manually adjust the autoscaling target without any automation. </li> </ul>"},{"location":"aws/concepts/autoscaling/#other-considerations","title":"Other Considerations","text":"<p>Adding capacity is generally an easy process. For compute, it's just a matter of launching new workers from static images or automated standup processes.</p> <p>Reducing capacity can be tricky depending on the application. Web applications generally have their requests clean up to prepare for termination within 30 seconds. Load balancers are often used to drain requests off instances and then terminate the instances \"cleanly\". Queue/batch workers, on the other hand, need to be done with their work, or stash their work somewhere before the node can be terminated. Otherwise, requests and/or data can be lost or incomplete.</p> <p>DynamoDB Provisioned Capacity has restrictions regarding how frequently it can be reduced (4 times per day at any time, plus any time when there hasn't been a reduction in the last hour). There are no restrictions regarding increasing capacity. Tables and Secondary Indexes are managed/scaled independently.</p> <p>Scaling cooldown can be the trickiest part of the process. It's generally best to aggressively scale up/out and conservatively scale down/in. A long cooldown process might be necessary when scaling out an application with a long startup process, but it can also block future scale out events, resulting in application instability. Scaling policies should be regularly evaluated and tuned.</p> <p>Contribute</p> <p>Contribute to this page on GitHub or join the <code>#cloud-costs-handbook</code> channel in the Vantage Community Slack.</p>"},{"location":"aws/concepts/credits/","title":"Credits on AWS","text":"<p>Most public cloud infastructure and service providers have a concept of credits. Credits are incentives typically given to customers opening up new accounts to attract them to build upon their platform. They allow you you to build, learn and get integrated into providers without have to spend money right from the beginning. </p> <p>Credit allotments usually are around $5,000 or $10,000 depending on the provider but can be as high as $100,000.</p>"},{"location":"aws/concepts/credits/#startup-credits-across-clouds","title":"Startup Credits Across Clouds","text":"<p>One strategy that is often used for especially cost-conscious startups for public cloud infrastructure providers who have the ability to easily move workloads is to receive credits from multiple providers and run workloads across different providers until credits expire across all of them. So for example, a startup may get $10,000 of AWS credits and $10,000 of GCP credits. A subset of customers will run their application on AWS until their $10,000 is completely utilized then migrate to GCP to use up $10,000 worth of credits there to get $20,000 in total free usage.</p> <p>Typically this is advised against because the operational overhead of running workloads across multiple clouds typically isn't worth it. The use-cases that this tends to work for is for very transferable or ephemeral workloads such as training models on GPUs or running containers with no associated state. </p>"},{"location":"aws/concepts/credits/#credit-expiration","title":"Credit Expiration","text":"<p>It's important to note that credits typically have a lifecycle tied to them that causes them to expire. Oftentimes this catches customers by surprise. Usually credits are granted on a 1 year basis which means if you have remaining credits that aren't utilized by the expiration term, they're automatically removed from your account. It's important to keep track of your credit expiration dates as to not be caught off-guard.</p> <p>Contribute</p> <p>Contribute to this page on GitHub or join the <code>#cloud-costs-handbook</code> channel in the Vantage Community Slack.</p>"},{"location":"aws/concepts/io-operations/","title":"I/O Operations (IOPS) on AWS | Cloud Cost Handbook","text":""},{"location":"aws/concepts/io-operations/#io-operations","title":"I/O Operations","text":"<p>I/O Operations (IOPS) are a relatively low level unit in AWS for measuring disk performance. The maximum size of an IOP is 256 KiB for SSD volumes and 1 GiB for HDD volumes. 1 GiB of storage is worth 3 IOPS so a 1,000 GiB EBS Volume has 3,000 IOPS available. When using these volume types you are charged for the amount of provisioned iops even if you don't fully utilize them.</p> <p>As indidicated on the EBS page:</p> <p>Provisioned IOPS SSD volumes use a consistent IOPS rate, which you specify when you create the volume, and Amazon EBS delivers the provisioned performance 99.9 percent of the time.</p> <p>The \"performance consistency\" between a Provisioned IOPS volume and a general prupose (<code>gp2</code>, <code>gp3</code>), throughput optimized (<code>st1</code>), or cold HDD (<code>sc1</code>) is going to be better for both random and sequential disk access. Note that for operations with \"large and sequential\" accesses, provisioned iops are likely less efficient than an <code>st1</code> volume.</p>"},{"location":"aws/concepts/io-operations/#iops-considerations","title":"IOPS Considerations","text":"<ul> <li>Volume Type There are multiple volume types with different impacts on IOPS.</li> <li>I/O Demand Most likely the workload has a bursty demand pattern, where consistently high throughput is not as important as meeting spikes of demand. As the workload deviates from this, provisioned IOPS become more important.</li> <li>Throughput Limits The instance will have an upper limit of throughput it can support. For example, an i2.xlarge can support up to 62,500 IOPS. If the number of Provisioned IOPS is even higher than this limit, it is a waste because the instance cannot use them all up.</li> </ul>"},{"location":"aws/concepts/io-operations/#optimal-provisioned-iops","title":"Optimal Provisioned IOPS","text":"<p>The most common cost waste with IOPS is having too many of them. It is commonly believed that the key to RDS is to have some amount of Provisioned IOPS. Happily, we do not have to guess.</p> <p>AWS suggests inspecting the <code>VolumeQueueLength</code> metric for CloudWatch. This metric is reported as IOPS, which means the formula is simple: if <code>VolumeQueueLength</code> is greater than the number of provisioned IOPS and latency is an issue, then you should consider increasing the number of provisioned IOPS.</p> <p>Contribute</p> <p>Contribute to this page on GitHub or join the <code>#cloud-costs-handbook</code> channel in the Vantage Community Slack.</p>"},{"location":"aws/concepts/regions/","title":"Regions Pricing","text":"<p>Pricing for public cloud infrastructure providers typically varies by geographic region. Depending on the nature of your applications, you may not have a choice but to be located as close to your users as possible for latency purposes. That being said, it is worth looking at pricing on a per region basis as there can be significant discounts on a per-region basis. </p> <p>The Instances pricing tool has prices for popular AWS services in all regions. To see a list of AWS regions, consult this reference list of AWS regions.</p> <p>Contribute</p> <p>Contribute to this page on GitHub or join the <code>#cloud-costs-handbook</code> channel in the Vantage Community Slack.</p>"},{"location":"aws/concepts/reserved-instances/","title":"Reserved Instances","text":"<p>Reserved Instances (oftentimes referred to as their abbreviation of RIs) are one of the most popular and high-impact cost reduction methods you can leverage for cutting your bill. Reserved Instances give you the ability to pay upfront for certain AWS services to receive a discount. As a result, if you are able to profile usage across your AWS account and know that you'll hit certain usage levels, Reserved Instances can typically save you money. </p> <p>Reserved Instances are availabile to a variety of AWS services such as EC2, ElastiCache and RDS. AWS Billing automatically applies your Reserved Instance discounted rate when attributes of your instance usage match attributes of an active Reserved Instance. For general compute usage (EC2, Fargate, etc.), Savings Plans are always preferred to Reserved Instances as they give you the same discount but are more flexible across all compute. </p> <p>It's important to note that Reserved Instances aren't actually separate instances. They are merely financial instruments that you buy and are automatically applied to your account. As a result, you can continue to spin up and use on-demand instances and purchase Reserved Instances concurrently. As on-demand instances match your Reserved Instance attributes, you'll automatically receive discounts. </p>"},{"location":"aws/concepts/reserved-instances/#reserved-instance-term","title":"Reserved Instance Term","text":"<p>AWS gives different discounts depending on the term that you pay upfront for. You can yield greater savings for paying upfront for longer terms but lose flexibility as a result. We find that smaller customers just getting started in their infrastructure journey tend to prefer 1-Year Reserved Instances whereas more mature organizations will leverage 3-Year Reserved Instances for the greatest savings as they can more accurately model and predict their usage. </p> <p>Contribute</p> <p>Contribute to this page on GitHub or join the <code>#cloud-costs-handbook</code> channel in the Vantage Community Slack.</p>"},{"location":"aws/concepts/rightsizing/","title":"Rightsizing","text":"<p>Rightsizing is a term used for identifying and augmenting certain resources for greater utilization and potential cost savings. Typically rightsizing occures when you're over-provisioned and can apply to a variety of services with some examples below:</p> <ul> <li>EC2 Instances: Oftentimes customers will choose one EC2 Instance that is over-allocated in terms the amount of vCPU and GB of RAM it is allocated. As a result, customers may be paying more on a per EC2-Instance basis. Customers who are able to identify opportunitites for rightsizing EC2 Instances can typically save significantly, especially if the EC2 Instance type chosen represents a large pool of instances. </li> <li>EBS Volumes: EBS Volumes are typically a large cost driver for many organizations and are often heavily under-utilized. EBS charges you for the amount of storage you have allocated versus utilize so its important to keep an eye on Volume utilization to rightsize and save accordinly. </li> <li>RDS Instances: RDS Instances are similar to EC2 Instances in that they're typically overprovisioned but rarely utilized appropriately. While RDS rightsizing can result in significant cost savings, databases tend to be one of the services that makes sense to leave overprovisioned that you can grow into as downtime for a database during a rightsizing process may not ultimatately be worth the organization cost. </li> <li>Container Services: ECS, Fargate and EKS allow you to run services of containers on a pool of underlying EC2 instances either managed by you or managed by AWS if you're using Fargate. Container Services are some of the hardest services to appropriately rightsize but can represent significant saving opportunities, especially for AWS Fargate. </li> </ul> <p>The first step in rightsizing is to have monitoring and observability in place to even know what your utilization is for these various services. Assuming you feel confident in your usage patterns and how they relate to utilization, your organization can begin to make some decision for potential area to rightsize. </p> <p>Contribute</p> <p>Contribute to this page on GitHub or join the <code>#cloud-costs-handbook</code> channel in the Vantage Community Slack.</p>"},{"location":"aws/concepts/savings-plans/","title":"Savings Plans","text":"<p>Savings Plans are a flexible pricing model offering discounted prices compared to On-Demand pricing, in exchange for a specific usage commitment. Savings Plans are typically the highest impact, lowest effort way of realizing savings on your AWS account. They are roughly the same concept as Reserved Instances but offer greater flexiblity as they 1) can be utilized across multiple compute services (i.e., EC2 and Fargate) and 2) you aren't locked into a specific instance family. Similar to Reserved Instances, there are greater discounts for prepaying for a longer term.</p> <p>After purchasing a Savings Plan, AWS Billing will automatically apply savings as corresponding on-demand resources match the conditions of your Savings Plans. Savings Plans are only applicable to usage across Amazon EC2, AWS Lambda, and AWS Fargate. Machine Learning Savings Plans (sometimes called SageMaker Savings Plans) are available for Sagemaker. Typically, customers will use Savings Plans for these services and Reserved Instances for other services that aren't covered such as RDS and ElastiCache.</p> <p>Contribute</p> <p>Contribute to this page on GitHub or join the <code>#cloud-costs-handbook</code> channel in the Vantage Community Slack.</p>"},{"location":"aws/concepts/tags/","title":"Tagging Resources","text":"<p>Tags are one of the most powerful (though often overlooked) tools that can assist with your ability to observe and allocate cloud costs as it relates to public cloud infrastructure providers like AWS, Azure and GCP. While different AWS accounts can be useful for separating resources and costs across different environments (production, staging, qa, test, etc) or teams/business-units, tags are helpful for segmenting costs as it relates to your application. We encourage customers to adopt tagging strategies as early on at their organizations as possible. Similar to an effective unit testing suite, over time tags can give you confidence in understanding where your costs are coming from. </p> <p>Tags on AWS consist of two different parts: a <code>key</code> and a <code>value</code>. As a basic example you can imagine an example <code>key</code> with the value of \"service\" and potential <code>value</code>s of \"front-end\", \"back-end\", \"search\" or \"cache\". Upon assigning tags to resources, you can get greater visibility into where your costs are coming from. Instead of seeing how your costs are trending in aggregate, you can see how each part of your application is growing assuming you've leveraged tags correctly. Additionally, tags can be part of your existing workflows and are typically very easy to accomodate in infrastructure-as-code configuration files such as CloudFormation or Terraform. </p>"},{"location":"aws/concepts/tags/#activating-cost-allocation-tags","title":"Activating Cost Allocation Tags","text":"<p>One of the more generally confusing experiences that customers experience on AWS is that tags are not incorporated into billing reports by default and need to be \"activated\". After you have assigned resources tags, here are the steps to \"activate\" the tags for them to be incorporated into billing data:</p> <p>To activate your tags</p> <ul> <li>Sign in to the AWS Management Console and open the Billing and Cost Management console at https://console.aws.amazon.com/billing/home?#/tags.</li> <li>In the navigation pane, choose Cost Allocation Tags.</li> <li>Select the tags that you want to activate.</li> <li>Choose Activate.</li> </ul> <p>After you create and apply tags to your resources, it can take up to 24 hours for the tags to appear in your reports. After you select your tags for activation, it can take up to 24 hours for tags to activate as well.</p> <p>Contribute</p> <p>Contribute to this page on GitHub or join the <code>#cloud-costs-handbook</code> channel in the Vantage Community Slack.</p>"},{"location":"aws/reference/aws-gpu-instances/","title":"AWS GPU Instances | Cloud Cost Handbook","text":"<p>This table is generated by <code>transform_gpus.py</code> in GitHub, with data from the Instances codebase.</p> <p>For more detailed information about matching CUDA compute capability, CUDA gencode, and ML framework version for various NVIDIA architectures, please see this up-to-date resource. The NVIDIA documentation also explains compute capability.</p> GPU Instance Model Compute Capability GPU Count CUDA Cores Memory g2.2xlarge NVIDIA GRID K520 3.0 1 3072 4 g2.8xlarge NVIDIA GRID K520 3.0 4 6144 16 g3s.xlarge NVIDIA Tesla M60 5.2 1 2048 8 g3.4xlarge NVIDIA Tesla M60 5.2 1 2048 8 g3.8xlarge NVIDIA Tesla M60 5.2 2 4096 16 g3.16xlarge NVIDIA Tesla M60 5.2 4 8192 32 g4dn.xlarge NVIDIA T4 Tensor Core 7.5 1 2560 16 g4dn.2xlarge NVIDIA T4 Tensor Core 7.5 1 2560 16 g4dn.4xlarge NVIDIA T4 Tensor Core 7.5 1 2560 16 g4dn.8xlarge NVIDIA T4 Tensor Core 7.5 1 2560 16 g4dn.16xlarge NVIDIA T4 Tensor Core 7.5 1 2560 16 g4dn.12xlarge NVIDIA T4 Tensor Core 7.5 4 10240 64 g4dn.metal NVIDIA T4 Tensor Core 7.5 8 20480 128 p2.xlarge NVIDIA Tesla K80 3.7 1 2496 12 p2.8xlarge NVIDIA Tesla K80 3.7 4 19968 96 p2.16xlarge NVIDIA Tesla K80 3.7 8 39936 192 p3.2xlarge NVIDIA Tesla V100 7.0 1 5120 16 p3.8xlarge NVIDIA Tesla V100 7.0 4 20480 64 p3.16xlarge NVIDIA Tesla V100 7.0 8 40960 128 p3dn.24xlarge NVIDIA Tesla V100 7.0 8 40960 256 g5.xlarge NVIDIA A10G 7.5 1 9616 24 g5.2xlarge NVIDIA A10G 7.5 1 9616 24 g5.4xlarge NVIDIA A10G 7.5 1 9616 24 g5.8xlarge NVIDIA A10G 7.5 1 9616 24 g5.16xlarge NVIDIA A10G 7.5 1 9616 24 g5.12xlarge NVIDIA A10G 7.5 4 38464 96 g5.24xlarge NVIDIA A10G 7.5 4 38464 96 g5.48xlarge NVIDIA A10G 7.5 8 76928 192 p4d.24xlarge NVIDIA A100 8.0 8 55296 320 p4de.24xlarge NVIDIA A100 8.0 8 55296 640 g5g.xlarge NVIDIA T4G Tensor Core 7.5 1 2560 16 g5g.2xlarge NVIDIA T4G Tensor Core 7.5 1 2560 16 g5g.4xlarge NVIDIA T4G Tensor Core 7.5 1 2560 16 g5g.8xlarge NVIDIA T4G Tensor Core 7.5 1 2560 16 g5g.16xlarge NVIDIA T4G Tensor Core 7.5 2 5120 32 g5g.metal NVIDIA T4G Tensor Core 7.5 2 5120 32 g4ad.xlarge AMD Radeon Pro V520 0 1 - 8 g4ad.2xlarge AMD Radeon Pro V520 0 1 - 8 g4ad.4xlarge AMD Radeon Pro V520 0 1 - 8 g4ad.8xlarge AMD Radeon Pro V520 0 2 - 16 g4ad.16xlarge AMD Radeon Pro V520 0 4 - 32"},{"location":"aws/reference/aws-product-codes/","title":"All AWS Product Codes | Cloud Cost Handbook","text":"<p>This table is generated by <code>get_products.py</code> in GitHub. It requires SSM access to run.</p> Product Code 1 AWS Account Management 2 AWS Amplify 3 AWS Amplify Admin 4 AWS App Mesh 5 AWS App Runner 6 AWS AppSync 7 AWS Application Cost Profiler 8 AWS Application Discovery Service 9 AWS Application Migration Service (MGN) 10 AWS Artifact 11 AWS Audit Manager 12 AWS Auto Scaling 13 AWS Backup 14 AWS Backup Gateway 15 AWS Backup Storage 16 AWS Batch 17 AWS Billing Conductor 18 AWS Budgets 19 AWS Certificate Manager 20 AWS Certificate Manager Private Certificate Authority 21 AWS Chatbot 22 AWS Chime Meetings SDK 23 AWS Cloud Map 24 AWS Cloud9 25 AWS CloudFormation 26 AWS CloudHSM 27 AWS CloudHSM 28 AWS CloudShell 29 AWS CloudTrail 30 AWS CodeArtifact 31 AWS CodeBuild 32 AWS CodeCommit 33 AWS CodeDeploy 34 AWS CodePipeline 35 AWS CodeStar 36 AWS CodeStar Notifications 37 AWS Compute Optimizer 38 AWS Config 39 AWS Control Tower 40 AWS Cost Explorer 41 AWS Cost and Usage Report 42 AWS Data Exchange 43 AWS Data Pipeline 44 AWS DataSync 45 AWS Database Migration Service 46 AWS DeepComposer 47 AWS DeepLens 48 AWS DeepRacer 49 AWS Device Farm 50 AWS Direct Connect 51 AWS Directory Service 52 AWS Elastic Beanstalk 53 AWS Elastic Disaster Recovery (DRS) 54 AWS Elemental MediaConnect 55 AWS Elemental MediaConvert 56 AWS Elemental MediaLive 57 AWS Elemental MediaPackage 58 AWS Elemental MediaPackage VOD 59 AWS Elemental MediaStore 60 AWS Elemental MediaStore Data Plane 61 AWS Elemental MediaTailor 62 AWS EventBridge Schemas 63 AWS Fargate 64 AWS Fault Injection Simulator 65 AWS Firewall Manager 66 AWS Global Accelerator 67 AWS Glue 68 AWS Glue DataBrew 69 AWS Ground Station 70 AWS Health APIs And Notifications 71 AWS IAM Access Analyzer 72 AWS IQ 73 AWS Identity and Access Management (IAM) 74 AWS Identity and Access Management Roles Anywhere 75 AWS Import/Export 76 AWS IoT (data plane) 77 AWS IoT 1-Click 78 AWS IoT 1-Click Devices Service 79 AWS IoT Analytics 80 AWS IoT Core 81 AWS IoT Device Advisor 82 AWS IoT Device Defender 83 AWS IoT Device Management 84 AWS IoT Events 85 AWS IoT Events Data 86 AWS IoT Fleet Hub 87 AWS IoT Greengrass 88 AWS IoT Secured Tunneling 89 AWS IoT SiteWise 90 AWS IoT Things Graph 91 AWS IoT TwinMaker 92 AWS Key Management Service 93 AWS Lake Formation 94 AWS Lambda 95 AWS License Manager 96 AWS License Manager User Subscriptions 97 AWS Mainframe Modernization 98 AWS Managed Services 99 AWS Marketplace 100 AWS Marketplace Catalog API 101 AWS Marketplace Commerce Analytics 102 AWS Marketplace Entitlement Service 103 AWS Marketplace Metering Service 104 AWS Migration Hub 105 AWS Migration Hub Refactor Spaces 106 AWS Mobile Service 107 AWS Network Firewall 108 AWS OpsWorks Stacks 109 AWS OpsWorks for Chef Automate 110 AWS OpsWorks for Chef Automate 111 AWS OpsWorks for Puppet Enterprise 112 AWS Organizations 113 AWS Outposts 114 AWS Panorama 115 AWS Personal Health Dashboard 116 AWS Price List Service 117 AWS Private 5G 118 AWS PrivateLink 119 AWS Proton 120 AWS Recycle Bin 121 AWS Resilience Hub 122 AWS Resource Access Manager (RAM) 123 AWS Resource Groups 124 AWS Resource Groups Tagging API 125 AWS RoboMaker 126 AWS S3 Control 127 AWS S3 for Outposts 128 AWS Savings Plans 129 AWS Secrets Manager 130 AWS Security Hub 131 AWS Security Token Service 132 AWS Server Migration Service (SMS) 133 AWS Serverless Application Repository 134 AWS Service Catalog 135 AWS Service Catalog App Registry 136 AWS Shield 137 AWS Signer 138 AWS Single Sign-On 139 AWS Single Sign-On (SSO) OpenID Connect Service 140 AWS Snowball 141 AWS Snowcone 142 AWS Snowmobile 143 AWS Step Functions 144 AWS Storage Gateway 145 AWS Support 146 AWS Support App 147 AWS Systems Manager 148 AWS Systems Manager Incident Manager Contacts 149 AWS Transfer Family 150 AWS Transit Gateway 151 AWS Trusted Advisor 152 AWS VPN 153 AWS WAF 154 AWS WAF Regional 155 AWS Well-Architected Tool 156 AWS X-Ray 157 AWSIdentityStore 158 AWSdlm 159 Alexa for Business 160 Amazon API Gateway 161 Amazon API Gateway V2 162 Amazon AppConfig 163 Amazon AppFlow 164 Amazon AppStream 2.0 165 Amazon Athena 166 Amazon Augmented AI (A2I) 167 Amazon Aurora 168 Amazon Braket 169 Amazon Chime 170 Amazon Chime Messaging 171 Amazon Chime SDK Media Pipelines 172 Amazon Cloud Directory 173 Amazon CloudFront 174 Amazon CloudSearch 175 Amazon CloudWatch 176 Amazon CloudWatch Application Insights 177 Amazon CloudWatch Events 178 Amazon CloudWatch Evidently 179 Amazon CloudWatch Logs 180 Amazon CloudWatch Synthetics 181 Amazon CodeGuru 182 Amazon CodeGuru Reviewer 183 Amazon Cognito 184 Amazon Cognito Identity User Pools 185 Amazon Cognito Sync 186 Amazon Comprehend 187 Amazon Comprehend Medical 188 Amazon Connect 189 Amazon Connect Contact Lens 190 Amazon Connect Customer Profiles 191 Amazon Connect Participant Service 192 Amazon Connect Wisdom Service 193 Amazon Detective 194 Amazon DevOps Guru 195 Amazon DocumentDB (with MongoDB compatibility) 196 Amazon DynamoDB 197 Amazon DynamoDB Accelerator 198 Amazon DynamoDB Streams 199 Amazon EC2 Auto Scaling 200 Amazon EMR Containers 201 Amazon EMR Serverless 202 Amazon ElastiCache 203 Amazon Elastic Block Store (EBS) 204 Amazon Elastic Compute Cloud (EC2) 205 Amazon Elastic Container Registry (ECR) 206 Amazon Elastic Container Registry Public 207 Amazon Elastic Container Service (ECS) 208 Amazon Elastic File System (EFS) 209 Amazon Elastic Inference 210 Amazon Elastic Kubernetes Service (EKS) 211 Amazon Elastic MapReduce (EMR) 212 Amazon Elastic Transcoder 213 Amazon Elasticsearch Service 214 Amazon EventBridge 215 Amazon FSx 216 Amazon FSx for Lustre 217 Amazon FSx for NetApp ONTAP 218 Amazon FSx for OpenZFS 219 Amazon FSx for Windows File Server 220 Amazon FinSpace 221 Amazon FinSpace Beta API 222 Amazon Forecast 223 Amazon Forecast Query 224 Amazon Fraud Detector 225 Amazon GameLift 226 Amazon GameSparks 227 Amazon Glacier 228 Amazon GuardDuty 229 Amazon HealthLake 230 Amazon Honeycode 231 Amazon IVS 232 Amazon IVS Chat 233 Amazon Inspector 234 Amazon Inspector 235 Amazon Kendra 236 Amazon Keyspaces (for Apache Cassandra) 237 Amazon Kinesis Data Analytics 238 Amazon Kinesis Data Firehose 239 Amazon Kinesis Data Streams 240 Amazon Kinesis Video Streams 241 Amazon Lex 242 Amazon Lex Model Building Service 243 Amazon Lex Model Building V2 244 Amazon Lightsail 245 Amazon Location Service 246 Amazon Lookout for Equipment 247 Amazon Lookout for Metrics 248 Amazon Lookout for Vision 249 Amazon Lumberyard 250 Amazon MQ 251 Amazon Machine Learning 252 Amazon Macie 253 Amazon Managed Blockchain 254 Amazon Managed Grafana 255 Amazon Managed Service for Prometheus 256 Amazon Managed Streaming for Apache Kafka 257 Amazon Managed Workflows for Apache Airflow 258 Amazon Mechanical Turk 259 Amazon MemoryDB for Redis 260 Amazon Neptune 261 Amazon Nimble Studio 262 Amazon Personalize 263 Amazon Pinpoint 264 Amazon Pinpoint Email Service 265 Amazon Pinpoint SMS Voice 266 Amazon Pinpoint SMS Voice V2 267 Amazon Pinpoint SMS and Voice Service 268 Amazon Polly 269 Amazon QLDB Session 270 Amazon Quantum Ledger Database (QLDB) 271 Amazon QuickSight 272 Amazon RDS on VMware 273 Amazon Redshift 274 Amazon Rekognition 275 Amazon Relational Database Service (RDS) 276 Amazon Route 53 277 Amazon Route 53 Domains 278 Amazon Route 53 Resolver 279 Amazon SageMaker 280 Amazon SageMaker 281 Amazon SageMaker Feature Store Runtime 282 Amazon Simple Email Service (SES) 283 Amazon Simple Notification Service (SNS) 284 Amazon Simple Queue Service (SQS) 285 Amazon Simple Storage Service (S3) 286 Amazon Simple Workflow Service (SWF) 287 Amazon SimpleDB 288 Amazon Sumerian 289 Amazon Textract 290 Amazon Timestream 291 Amazon Transcribe 292 Amazon Transcribe Medical 293 Amazon Translate 294 Amazon Virtual Private Cloud (VPC) 295 Amazon Voice ID 296 Amazon WorkDocs 297 Amazon WorkMail 298 Amazon WorkMail Message Flow 299 Amazon WorkSpaces 300 Amazon WorkSpaces Application Manager 301 Amazon WorkSpaces Web 302 AmazonApiGatewayManagementApi 303 AmazonAppIntegrationService 304 AmplifyUIBuilder 305 AppConfigData 306 ChimeSDK Identity 307 CloudEndure Disaster Recovery 308 CloudEndure Migration 309 CodeStar Connections 310 EC2 Image Builder 311 Elastic Load Balancing 312 FreeRTOS 313 IoTWirelessConnectivity 314 Managed Streaming for Kafka Connect Engine 315 Migration Hub Strategy Recommendations 316 NetworkManager 317 RDS Data 318 RUMControlPlaneLambda 319 Red Hat OpenShift Service on AWS (ROSA) 320 Redshift Data API Service 321 SSM Incidents 322 Service Quotas 323 SnowDeviceManagement 324 VMware Cloud on AWS"},{"location":"aws/reference/aws-regions/","title":"All AWS Regions | Cloud Cost Handbook","text":"<p>This is a list of AWS Regions and their API names from the Instances codebase. Ideally a boto3 script could generate these.</p> Region API Name Region af-south-1 Africa (Cape Town) ap-east-1 Asia Pacific (Hong Kong) ap-south-1 Asia Pacific (Mumbai) ap-northeast-3 Asia Pacific (Osaka) ap-northeast-2 Asia Pacific (Seoul) ap-southeast-1 Asia Pacific (Singapore) ap-southeast-2 Asia Pacific (Sydney) ap-southeast-3 Asia Pacific (Jakarta) ap-northeast-1 Asia Pacific (Tokyo) ca-central-1 Canada (Central) eu-central-1 EU (Frankfurt) eu-west-1 EU (Ireland) eu-west-2 EU (London) eu-west-3 EU (Paris) eu-north-1 EU (Stockholm) eu-south-1 EU (Milan) me-south-1 Middle East (Bahrain) me-central-1 Middle East (UAE) sa-east-1 South America (Sao Paulo) us-east-1 US East (N. Virginia) us-east-2 US East (Ohio) us-west-1 US West (N. California) us-west-2 US West (Oregon) us-gov-west-1 AWS GovCloud (US-West) us-gov-east-1 AWS GovCloud (US-East) <p>Contribute</p> <p>Contribute to this page on GitHub or join the <code>#cloud-costs-handbook</code> channel in the Vantage Community Slack.</p>"},{"location":"aws/services/batch-pricing/","title":"Batch Pricing | Cloud Cost Handbook","text":"<p>AWS Batch Pricing Page</p>"},{"location":"aws/services/batch-pricing/#summary","title":"Summary","text":"<p>AWS Batch combines job scheduling and job execution into one managed service. Example Batch workloads include video rendering, log file ingestion, model training, simulation, and cosmology. Under the hood, Batch provisions EC2 or Fargate instances and executes containerized jobs on them.</p> <p>Users set a range of vCPUs and memory that are needed to execute the job. You can also choose specific instance types, which can be helpful for cost optimizations. For both EC2 and Fargate jobs it is possible to select on-demand or spot instances. Job execution itself can be managed with scheduling, allocation, and parallelization parameters.</p>"},{"location":"aws/services/batch-pricing/#pricing-dimensions","title":"Pricing Dimensions","text":"<p>Batch is free!</p> <p>AWS Batch only consumes the underlying EC2 or Fargate resources, however it does not break these out in the bill. If Batch is pointed at existing EC2 instances, in other words the Batch Compute Environment is <code>UNMANAGED</code>, the cost of the Batch jobs will be the elapsed time they run on the instance.</p> <p>To view the cost of a job in a <code>MANAGED</code> Batch environment, you must inspect the ECS tasks that are associated with it. You can view the cost of AWS batch jobs through ECS in Cost Reports.</p> <p>Another technique is to add a tag to the Compute Environment that is created to run the Batch job in. This does not allow you to track costs down to the job level.</p>"},{"location":"aws/services/batch-pricing/#where-jobs-should-run","title":"Where Jobs Should Run","text":"<p>One consideration is whether Batch is even the right tool for the job, and if so what compute type is preferred. The table below shows various options for running batch workloads on AWS, and the constraints that come with each.</p> Lambda Fargate (Spot) Fargate EC2 (Spot) EC2 Job Length &lt;15 mins 5 - 10 mins 5 - 10 mins 5 - 45 mins Hours Compute Limits Lambda Runtime Only &lt;4 vCPUs, &lt;30 GiB memory, no GPU &lt;4 vCPUS, &lt;30 GiB mem, no GPU None None Startup Time &lt;1 sec 30 - 90 secs 30 - 90 secs 5 - 15 mins 5 - 15 mins Job is Fault Tolerant No Yes No Yes No"},{"location":"aws/services/batch-pricing/#batch-cost-optimization-tips","title":"Batch Cost Optimization Tips","text":"<p>AWS recommends a few techniques to lower costs for Batch jobs:</p> <ul> <li>The most cost effective allocation strategy for non interrupatable workloads is <code>BEST_FIT</code>. This strategy is sensitive to capacity constraints however and so an entire workload may have to wait for available machines. To avoid this, <code>BEST_FIT_PROGRESSIVE</code> tries to find the best instances but falls back to less cost efficient instances that will still complete the job (e.g. have the minimum required number of vCPUs). For Fargate and EC2 Spot workloads, <code>SPOT_CAPACITY_OPTIMIZED</code> uses the same auto scaling algorithm as Spot Fleets to get the best price.</li> <li>Use smaller containers and image layers. Loading each container consumes compute time for the job. Furthermore, pulling containers across NAT Gateways will rack up data transfer charges. Prefer PrivateLink for pulling containers.</li> <li>Use multiple availability zones. All things considered, <code>BEST_FIT_PROGRESSIVE</code> will find the cheapest AZ to run the workload in, so do not artificially limit yourself here.</li> </ul> <p>Contribute</p> <p>Contribute to this page on GitHub or join the <code>#cloud-costs-handbook</code> channel in the Vantage Community Slack.</p>"},{"location":"aws/services/cloudfront-pricing/","title":"Cloudfront Pricing | Cloud Cost Handbook","text":"<p>Amazon CloudFront Pricing Page</p>"},{"location":"aws/services/cloudfront-pricing/#summary","title":"Summary","text":"<p>Amazon CloudFront is a content delivery network (CDN) service used to distribute and cache traffic from one region to multiple geographic endpoints globally. Every CloudFront distribution includes an origin which is used to pull the original data from. An origin will typically be an S3 bucket or Load Balancer Endpoint. The traffic is distributed globally to speed up the access to an application which recieves visitors from across the globe. CloudFront Distributions are billed based on the amount of traffic they request from the origin, distribute out to the internet as well as per request processed. Distribution out to the internet is priced differently depending on the region which it is accessed. Regions are grouped into geographic regions. When creating a distribution it is possible to select which regions CloudFront will serve traffic from.</p>"},{"location":"aws/services/cloudfront-pricing/#pricing-dimensions","title":"Pricing Dimensions","text":"Dimension Description Transfer Out to Internet Distributions are billed per GB of data transfered out of a geographic area to the internet. The prices are tiered and are lower the more traffic is transferred. Regional Data Transfer Out to Origin Distributions are billed per GB of data transfer from the distribution back to the origin. The prices are a flat-rate and dependent on their geographic area. Per Request Distributions are billed per 10,000 requests and are different rates based on whether the request is HTTP or HTTPS. If origin shield is configured there is an additional charge per 10,000 requests and are a standard rate regardless of protocol. Both are priced differently depending on geographic area."},{"location":"aws/services/cloudfront-pricing/#origin-shield","title":"Origin Shield","text":"<p>Origin Shield can be enabled in order to reduce the amount of traffic being served directly from the origin. Origin shields are not available in every region.</p>"},{"location":"aws/services/cloudfront-pricing/#cloudfront-security-savings-bundle","title":"CloudFront Security Savings Bundle","text":"<p>The CloudFront Security Savings Bundle is a simple way to save up to 30% on the CloudFront charges on your AWS bill when you make a 1-year upfront commitment with no service-level configuration changes needed. You're billed in equal installments over the 12 months, starting from the time you purcahse the security savings bundle. Once you purchase the CloudFront Security Savings Bundle, the savings are automatically applied to your bill. If you're familiar with Savings Plans or Reserved Instances, this is essentially the CloudFront equivalent to those conceptually speaking. </p> <p>The reason for this being named a \"bundle\" is that by making this purchase you also get credits towards the AWS Web Application Firewall (WAF) service. Ten percent of the amount you pay in committed use for a CloudFront Security Savings Bundle will be granted toward AWS WAF. So for example if you pay $500 for a CloudFront Security Savings Bundle, $50 will also be applied towards AWS WAF. </p>"},{"location":"aws/services/cloudfront-pricing/#custom-pricing","title":"Custom Pricing","text":"<p>For customers who are willing to make certain minimum traffic commits (typically 10 TB/month or higher) they can contact AWS and negotiate custom discounted rates.</p>"},{"location":"aws/services/cloudfront-pricing/#cloudfront-versus-cloudflare","title":"CloudFront Versus Cloudflare","text":"<p>Cloudflare1 is an edge network that offers a number of different performance, availability and security services. One of those services is an edge caching service that offer effectively the same service as Amazon CloudFront. The most important distinction between CloudFront and Cloudflare is not a technical differentiation but a business model differentiation. CloudFront utilizes a metered pricing model whereby you pay based on the amount of traffic that is served via the CloudFront service.2 Cloudflare, on the otherhand, offers flat-rate pricing for its service without any bandwidth caps.3 </p> <p>What this means is that as a customer of Cloudflare's Business plan, you can pay $200 per month and delivery unlimited traffic via the Cloudflare CDN. Seems too good to be true? Feel free to browse the official Cloudflare community where this question is asked and answered multiple times.</p>"},{"location":"aws/services/cloudfront-pricing/#considerations","title":"Considerations","text":"<p>Price is not the only consideration that goes into making a decision about whether to utilize CloudFront or a competing CDN service. Performance, availability, user experience, support and legal compliance are other factors that will factor into the decision to utilize one service over another.</p>"},{"location":"aws/services/cloudfront-pricing/#availability","title":"Availability","text":"<p>In order to offer customers unlimited bandwidth, Cloudflare utilizes service degradation based on their plan levels to prioritize higher tier customers in the event of a service degredation. The two most common service degradations for Cloudflare are either a DDoS attack that is overwhelming one or more points-of-presence (PoP) in the network or a legitimate surge in traffic due to any number of events. </p> <p>When the resources for a PoP are being depleted and service is being degraded, Cloudflare will choose to route traffic for customers out of that location based on the plan level they are subscribed to. Free traffic will be routed away from the PoP first, then Pro, Business, etc. The effect of having traffic routed out of a specific PoP is that users that are closest to the PoP will have some level of service degredation since they will instead have their traffic served from a PoP that is farther away than their most ideal PoP. In locations where the next nearest available PoP is close this degredation will be practically unnoticable. In locations where the next available PoP is topologically distant service degredation can potentially be significant.</p>"},{"location":"aws/services/cloudfront-pricing/#technical","title":"Technical","text":"<p>In the scenario that you are utilizing CloudFront and have an Amazon service designated as the origin for the content being served, typically this would be an S3 bucket or maybe EC2 with an attached EBS volume, you should consider that by switch from CloudFront as your CDN to Cloudflare you will incur egress charges for data transfer from AWS to Cloudflare. AWS does not charge customers any egress fees when moving content from an AWS service like S3 or EC2 to CloudFront.4 The amount of charges will largely be dependent on your particular services cache hit ratio. The higher the cache hit ratio, the less cache misses that will incur AWS egress charges.</p> <p>This practice favors pairing CloudFront with an AWS service as origin. That being said, for most customers with significant  CloudFront traffic they will still come out on top by considering a flat-rate priced CDN plan.</p> <p>On top of this, you can also consider moving your content off of an AWS service to a provider in the Bandwidth Alliance. By utilizing the Cloudflare CDN service and a Bandwidth Alliance partner as the content origin, you can take advantage of the flat-rate pricing of the Cloudflare self-serve plans and eliminate all egress costs between Cloudflare and your origin provider of choice. This effectively gives you the same benefit that AWS offers customer of no egress charges between an AWS service and CloudFront but with the power of the flat-rate pricing that is available via the Cloudflare self-serve plans. Further details can be found at in the S3 service article of the Cloud Cost Handbook.</p>"},{"location":"aws/services/cloudfront-pricing/#sales","title":"Sales","text":"<p>Another side effect of subscribing to a self-serve plan from Cloudflare is that users of these plans are used as part of the sales funnel for the Cloudflare sales team. What this means is that by signing up for Cloudflare you are giving your contact information that can be utilized by the sales team in order for them to contact you about other Cloudflare services and offerings. </p> <p>The important thing to remember is that, as long as you aren't breaking the Cloudflare Terms of Service (ToS) they cannot force you to purchase any additional services.</p> <p></p> <p>Contribute</p> <p>Contribute to this page on GitHub or join the <code>#cloud-costs-handbook</code> channel in the Vantage Community Slack.</p> <ol> <li> <p>This guide is calling special attention to Cloudflare and no other vendors in this space due to the unique offerings that Cloudflare has that no other provider offers. Specifically, that they offer self-serve plans with flat-rate pricing and no bandwidth caps. If you are aware of any other services with a similar offering, please submit an issue or pull request and we will update the guide.\u00a0\u21a9</p> </li> <li> <p>Direct link to CloudFront pricing that details metered pricing model: https://aws.amazon.com/cloudfront/pricing/\u00a0\u21a9</p> </li> <li> <p>Direct link to the Cloudflare Terms of Service for the self-serve plans (i.e. the Free, Pro and Business plans):https://www.cloudflare.com/terms/\u00a0\u21a9</p> </li> <li> <p>\"If you are using an AWS origin, effective December 1, 2014, data transferred from origin to edge locations (Amazon CloudFront \"origin fetches\") will be free of charge.\" https://aws.amazon.com/cloudfront/pricing/\u00a0\u21a9</p> </li> </ol>"},{"location":"aws/services/cloudwatch-pricing/","title":"CloudWatch Pricing | Cloud Cost Handbook","text":"<p>Amazon CloudWatch Pricing Page</p>"},{"location":"aws/services/cloudwatch-pricing/#summary","title":"Summary","text":"<p>Amazon CloudWatch is a logging, monitoring and observability service. As with most monitoring/observibility tools the cost of service is based on the amount of data that is collected and stored as well as a number of other factors. CloudWatch is no different. For most use-cases, the largest CloudWatch costs are made up of the number of metrics and logs that a user is ingesting and storing. </p> <p>Oftentimes CloudWatch is leveraged automatically by other AWS services for metric and log storage. Users are sometimes surprised when they spin up a number of unrelated services which they accounted for during planning but are then greeted with an accompanying spike in CloudWatch costs that they didn't account for.</p> <p>CloudWatch stores and process data from an umbrella of different AWS services which means that sometimes it isn't obvious why the overall CloudWatch bill has increased. Diving into subcategory costs can help shed light on which other AWS services are causing CloudWatch costs to increase.</p>"},{"location":"aws/services/cloudwatch-pricing/#pricing-dimensions","title":"Pricing Dimensions","text":"Dimension Description Custom Metric Storage AWS charges you for the number of custom metrics you store with them per month. CloudWatch's unit pricing is progressive; the first 10,000 metrics tracked is $0.30 per metric per month, the next 240,000 costs $0.10 and so on.1 This gives users with large number of metrics automatic economies of scale as they grow the number of metrics tracked. Note: Pricing is dependant on the region where you store your metrics.2 CloudWatch API Requests AWS charges you for the following API requests: <code>GetMetricData</code>, <code>GetInsightRuleReport</code>, <code>GetMetricWidgetImage</code>, <code>GetMetricStatistics</code>, <code>ListMetrics</code>, <code>PutMetricData</code>, <code>GetDashboard</code>, <code>ListDashboards</code>, <code>PutDashboard</code> and <code>DeleteDashboards</code>. For most AWS services there is no API charge for sending metrics. A user would normally be charged by the CloudWatch API for ingesting metrics from a non-AWS service or for a third-party infrastructure monitoring/observibility tool reading from the API to collect metrics. Pricing is dependant on the region where CloudWatch is deployed.3 CloudWatch Dashboards AWS charges $3.00 per month per CloudWatch dashboard. CloudWatch Alarms CloudWatch alarms are priced based on the resolution of the alarm (60 seconds versus 10 seconds) and if you need to combine multiple alarms together into a more complex alarm like anomoly detection or a composite alarm. Pricing is dependant on the region where CloudWatch is deployed.3 CloudWatch Logs AWS charges you for two components as it relates to CloudWatch Logs: (1) ingestion and (2) storage. CloudWatch Events AWS charges you for CloudWatch Events which are changes in your AWS environment. For example, you can trigger an event whenever an EC2 instance is created. You are charged a rate per one million events. CloudWatch Contributor Insights Contributor Insights are only available for CloudWatch Logs and DynamoDB. For CloudWatch Logs, Contributor Insights are priced per-rule per-month, and for every million log events per month that match your rule. For DynamoDB, Contributor Insights are priced per-rule per-month and for every million DynamoDB Events, which occur when items are read from or written to your DynamoDB table. CloudWatch Canaries Canaries are priced based on the number of runs. Pricing is very specific to region. Be sure to check where you are running your CloudWatch Canaries to be aware of the price for that region. <p>Contribute</p> <p>Contribute to this page on GitHub or join the <code>#cloud-costs-handbook</code> channel in the Vantage Community Slack.</p> <ol> <li> <p>Price is based on US East (Ohio) region as of July 28, 2021. See footnote below for comment about pricing per region.\u00a0\u21a9</p> </li> <li> <p>Or at least this is what the CloudWatch pricing page states. If you click through all of the regions the prices are all the same for custom metric storage as of July 28, 2021.\u00a0\u21a9</p> </li> <li> <p>Pricing is fairly uniform across regions. Special regions like Sao Paulo and GovCloud diverge from the standard pricing.\u00a0\u21a9\u21a9</p> </li> </ol>"},{"location":"aws/services/dynamodb-pricing/","title":"DynamoDB Pricing | Cloud Cost Handbook","text":"<p>Amazon DynamoDB Pricing Page</p>"},{"location":"aws/services/dynamodb-pricing/#summary","title":"Summary","text":"<p>DynamoDB is Amazon's primary managed NoSQL database service.</p> <p>It offers single-digit-millisecond latency, scales to effectively unlimited requests-per-second &amp; storage, and has (largely) predictable pricing.</p> <p>DynamoDB, like most NoSQL datastores, differs substantially from relational databases - it can only be queried via primary key attributes on the base table &amp; indexes.</p>"},{"location":"aws/services/dynamodb-pricing/#pricing-dimensions","title":"Pricing Dimensions","text":"Dimension Options Description Docs Billing Mode <code>On Demand, Provisioned Throughput</code> Choose between paying per read/write or per allocated requests-per-second-throughput Docs Write Type <code>Standard, Transactional</code> Transactional operations allow ACID guarantees at twice the standard cost Docs Read Type <code>Eventually Consistent, Strongly Consistent, Transactional</code> Dynamo reads are by default Eventually Consistent - when you read from a table, the response might not reflect the results of a recently completed write. Docs Read Operation <code>GetItem, Scan, Query</code> Scans return the entire contents of a table; Queries allow a much faster &amp; cheaper read of a subsection of the table Docs Indexes <code>None, Local Secondary Index, Global Secondary Index</code> Indexes allow an alternate set of <code>partition_key</code> + <code>sort_key</code> to be used for queries Overview"},{"location":"aws/services/dynamodb-pricing/#billing-mode","title":"Billing Mode","text":"<p>\"Use on-demand until it hurts\" - Alex DeBrie, quoting Jared Short</p> <p>Provisioned Throughput is cheaper if you have a meaningful number of reads/writes distributed evenly across time. Any reads/writes above the provisioned threshold will fail, so it is not well suited to bursty or unpredictable workloads.</p> <p>Provisioned Throughput includes optional Auto-Scaling if throughput thresholds are being exceeded (Docs).</p> <p>AWS Free Tier includes 25 reads/writes-per-second of Provisioned Throughput (across any # of tables), but does not include any On Demand mode usage.</p> Billing Mode Unit Unit Definition On Demand Read Request Unit (RRU) read two &lt;4KB items, eventually consistent On Demand Write Request Unit (WRU) write one &lt;1KB item Provisioned Throughput Read Capacity Unit (RCU) two reads per second (&lt;4KB items), eventually consistent Provisioned Throughput Write Capacity Unit (WCU) one write per second (&lt;1KB item)"},{"location":"aws/services/dynamodb-pricing/#write-type","title":"Write Type","text":"<p>Standard writes are relatively straightforward and include single item writes (<code>table.put_item</code>) and batch writes (<code>batch.put_item</code>).</p> <p>Transactions (<code>client.execute_transaction</code>) group up to 25 writes (or reads, updates, or deletes) together and guarantee that they succeed or fail together.</p> <p>For a given write of an item up to 1 KB in size:</p> Type Cost Standard single item 1 WRU Standard batch 1 WRU (per item) Transactional 2 WRU (2x) Oversize 4 KB item 4 WRU (4x, size dependent)"},{"location":"aws/services/dynamodb-pricing/#read-type","title":"Read Type","text":"<p>Part of what makes DynamoDB a compelling offering is its hybrid approach to the CAP theorem1 - it can adjust between eventually and strongly consistent as needed.</p> <p>Wherever acceptable to the business needs and current data modeling, it is faster and cheaper to use eventually consistent reads.</p> <p>That said, some business logic unequivocally dictates strongly consistent reads (for example: an ATM reading a customer's balance).</p> <p>For a given read of an item up to 4 KB in size:</p> Type Cost Eventually Consistent 0.5 RRU Strongly Consistent 1 RRU (2x) Transactional 2 RRU (4x)"},{"location":"aws/services/dynamodb-pricing/#read-operation","title":"Read Operation","text":"<p>Getting a single item is as simple as providing its <code>partition_key</code> (and <code>sort_key</code>, if the table has one)</p> <p>Queries, however, are much more involved. NoSQL databases like DynamoDB can require significant upfront data modeling work to enable the query flexibility that SQL-based databases have by default.</p> <p>Scans require reading the entire table, and are correspondingly slow and expensive. Wherever possible, avoid scanning Dynamo tables.</p> Type Cost <code>GetItem</code> 1 RRU <code>Query</code> {# of items meeting query logic} RRU <code>Scan</code> {# of items in table} RRU"},{"location":"aws/services/dynamodb-pricing/#indexes","title":"Indexes","text":"<p>Every DynamoDB table has a <code>partition_key</code> (<code>pk</code>) and optional <code>sort_key</code> (<code>sk</code>) specified at the time of creation.</p> <p>Indexes allow alternate partition and sort keys to be used to query items. They may be created at any time and are automatically maintained as new items are written.</p> <p>Indexes can help control costs in two primary ways:</p> <ol> <li> <p>Queries on a new index return less unnecessary items (than the alternative/existing query) and thus cost less RRUs.</p> </li> <li> <p>Each index optionally allows a subset of item attributes to be projected to that index. Projecting a subset can save on read costs if items are regularly &gt;4 KB, but the projected attribute names+values sum to &lt;4KB.2</p> </li> </ol> Type Primary Key Attributes Base table Initial <code>pk</code> + optional <code>sk</code> Local Secondary Index (LSI) Initial <code>pk</code> + different <code>sk</code> Global Secondary Index (GSI) Different <code>pk</code> + optional different <code>sk</code> <p>Info</p> <p>The provisioned throughput settings of a global secondary index are separate from those of its base table</p>"},{"location":"aws/services/dynamodb-pricing/#other","title":"Other","text":"<p>DynamoDB tables can optionally enforce a Time To Live (TTL) on items in the table, such that they expire after that amount of time (guaranteed within +48 hours).</p> <p>Dynamo exposes the time-ordered sequence of item-level changes on a given table via DynamoDB Streams. Reading change-data from Streams is slightly cheaper per request than reading the table itself (on pay per use BillingMode). The first 2.5M reads per month are free.</p>"},{"location":"aws/services/dynamodb-pricing/#further-reading","title":"Further Reading","text":"<ul> <li>An overview of the architecture of DynamoDB can be found in the DynamoDB Paper</li> <li>You can, if you so choose, use a SQL-like syntax to interface with DynamoDB via the recently-launched PartiSQL support</li> </ul> <p>Contribute</p> <p>Contribute to this page on GitHub or join the <code>#cloud-costs-handbook</code> channel in the Vantage Community Slack.</p> <ol> <li> <p>The CAP Theorem is a computer science theorem that observes that a distributed datastore cannot guarantee all three of Consistency, Availability, and Partition Tolerance.\u00a0\u21a9</p> </li> <li> <p>If a query to an index with projection requests attribute values not in the projected values, it will incur twice the normal read cost, as the remaining attribute values must be fetched from the base table\u00a0\u21a9</p> </li> </ol>"},{"location":"aws/services/ebs-pricing/","title":"EBS Pricing | Cloud Cost Handbook","text":"<p>Amazon EBS Pricing Page</p>"},{"location":"aws/services/ebs-pricing/#summary","title":"Summary","text":"<p>Amazon Elastic Block Storage (EBS) is amazon's block storage offering that allows you to create \"Volumes\" which is the base primitive of everything related to EBS. There are multiple EBS \"Volume Types\" that offer different capabilites and have their own set of pricing. EBS costs are factored into the cost category of \"EC2-Other\" on your AWS bill which can oftentimes complicate understanding where these costs are coming from. </p> <p>It is important to note that you are charged for the amount of provisioned storage not utilized storage. So, for example, if you create a 20GB EBS Volume and only utilize 1GB of it, you are still charged for all 20GB. </p>"},{"location":"aws/services/ebs-pricing/#pricing-dimensions","title":"Pricing Dimensions","text":"Dimension Description Volume Storage Hours When you create an EBS Volume you allocate a certain amount of storage to it. Ultimately the main cost of an EBS Volume is the result of the amount of hours you're using an EBS Volume and the size you allocate. Volume Type EBS has different types of Volume Types which are documented below. Each Volume Type has different rates. Provisioned IOPS Certain EBS Volume types (io2, io2) allow you to specific an amount of provisioned input/output operations per second which is abbreviated as IOPS and pronounced as \"eye-ops\". When using these volume types you are charged for the amount of provisioned iops even if you don't fully utilize them. Amazon EBS Snapshots Amazon EBS Snapshots are a point in time copy of your block volume data. EBS Snapshots are stored incrementally, which means you are billed only for the changed blocks stored. EBS Snapshot API Requests EBS charges you for the amount of API calls you make for snapshots. These are charged in increments of thousands of API requests."},{"location":"aws/services/ebs-pricing/#volume-types","title":"Volume Types","text":"<p>Amazon EBS offers a few different Volume Types that have different pricing rates and functionality. Each EBS Volume Type is described below:</p> Volume Type Description General Purpose SSD (gp2, gp3) General Purpose SSD (gp3) volumes offer cost-effective storage that is ideal for a broad range of workloads. Provisioned IOPS (io1, io2) Provisioned IOPS SSD (io1 and io2) volumes are designed to meet the needs of I/O-intensive workloads, particularly database workloads, that are sensitive to storage performance and consistency. Provisioned IOPS SSD volumes use a consistent IOPS rate, which you specify when you create the volume, and Amazon EBS delivers the provisioned performance 99.9 percent of the time."},{"location":"aws/services/ebs-pricing/#stranded-volumes","title":"Stranded Volumes","text":"<p>Oftentimes, EBS Volumes are created in conjunction with other AWS resources such as EC2 instances but are de-coupled from the lifecycle of those other resources. One common pattern we see is that developers will create EC2 instances with EBS Volumes attached but when they delete the EC2 instance, they assume that the EBS Volume is destroyed accordingly. In larger-scale environments with autoscaling this problem can grow significantly as a part of an AWS bill.</p> <p>We recommend that you periodically profile for unattached or stranded EBS Volumes.</p> <p></p> <p>Contribute</p> <p>Contribute to this page on GitHub or join the <code>#cloud-costs-handbook</code> channel in the Vantage Community Slack.</p>"},{"location":"aws/services/ec2-other-pricing/","title":"EC2-Other Pricing | Cloud Cost Handbook","text":""},{"location":"aws/services/ec2-other-pricing/#summary","title":"Summary","text":"<p>EC2-Other is a category of AWS costs that typically causes the greatest amount of confusion for customers as it doesn't necessarily map to a single AWS service. EC2-Other encompasses the following costs:</p> Usage Type Description EBS Volume Usage Usage for EBS Volumes. EBS Snapshot Usage Usage for EBS Snapshots. CPU Credits from t2/t3/t4g EC2 instances T-family EC2 Instances can carry potential CPU credit charges as described more below. NAT Gateway Usage Hourly usage for NAT Gateways. Data Transfer Idle Elastic IP Address usage AWS charges you for unattached IP addresses. It's typically good hygiene to occasionally monitor for stranded resources and clean them up."},{"location":"aws/services/ec2-other-pricing/#stranded-resources","title":"Stranded Resources","text":"<p>Unused or stranded EBS Volumes and IP Addresses can add up over time especially if these resources are created automatically as part of an autoscaling service where they're spun up but not down. You should consider occasionally auditing your unattached EBS Volumes and IP addresses to see if you can clean them up to save costs.</p>"},{"location":"aws/services/ec2-other-pricing/#what-are-t2t3t4g-cpu-credit-charges","title":"What are t2/t3/T4g CPU credit charges?","text":"<p>T2, T3 and T4g instances have a concept of \"Unlimited mode\" whereby you are charged a per-vCPU hour for bursting into this CPU usage. If you are leveraging these EC2 Instance Types with <code>unlimited</code> mode enabled, you should consider keeping an eye on these costs. Depending on how much your costs trend here, you may want to consider \"rightsizing\" to a different instance type that is allocated additional CPU.</p> <p></p> <p>Contribute</p> <p>Contribute to this page on GitHub or join the <code>#cloud-costs-handbook</code> channel in the Vantage Community Slack.</p>"},{"location":"aws/services/ec2-pricing/","title":"EC2 Pricing | Cloud Cost Handbook","text":"<p>Amazon EC2 Pricing Page</p>"},{"location":"aws/services/ec2-pricing/#summary","title":"Summary","text":"<p>Amazon EC2 (Elastic Cloud Compute) is Amazon\u2019s most popular service and usually one of the top cost centers for most companies. Amazon EC2 allows customers to create virtual private servers and has different pricing depending on the \u201cinstance type\u201d you use. Instance types are grouped into families with varying generations. Each instance type has a different mix of underlying hardware, allocated resources and as a result: pricing. Additionally, depending on the underlying software running on the EC2 instance you may be charged different rates.</p>"},{"location":"aws/services/ec2-pricing/#pricing-dimensions","title":"Pricing Dimensions","text":"Dimension Description Instance Type Usage EC2 instance types are billed on one second increments, with a minimum of 60 seconds. For certain instance types with pre-installed software, you are billed in increments of hours. Instance Type Lifecycle EC2 has different lifecycle types - the two most often used are on-demand and spot. These concepts are discussed more in-depth below. AMI AMI stands for Amazon Machine Images. Depending on the AMI you use (i.e., Linux vs Windows) you potentially pay an additional amount of money on top of the instance type base usage."},{"location":"aws/services/ec2-pricing/#on-demand-vs-spot","title":"On-Demand vs Spot","text":"<p>By default, EC2 instances are launched in \"on-demand\" mode and charged accompanying on-demand rates which are the most expensive. AWS also offers \"Spot\" instances which can offer significant cost savings by using unused additional compute capacity. However, Spot tends to only work for fault-tolerant workloads as AWS can pre-empt and terminate these instances within two minutes if need be. </p> <p>Depending on your application's needs, you can consider using Spot instances for significant cost savings in the event you are comfortable with these instances being terminated. In general, your application's architecture should be comfortable with either 1) there being no spot instances available or 2) these instances being terminated. </p>"},{"location":"aws/services/ec2-pricing/#autoscaling","title":"Autoscaling","text":"<p>EC2 autoscaling is provided by a primitive named Autoscaling Groups. Autoscaling Groups have lifecycle hooks to accommodate complex workflows regarding instance creation or termination and can support multiple instance types or spot instances using a Mixed Instance Policy. New instances are added based on a launch template (or launch config). This can be a challenge for organizations without good practices around creating machine images or automation for standing up applications.</p>"},{"location":"aws/services/ec2-pricing/#rightsizing","title":"Rightsizing","text":"<p>Rightsizing refers to the process of ensuring that you're using the proper instance type suited for your application or workload. For example if you're using the largest instance type in a particular family but not using the CPU, Storage and Memory allocated to it fully you may be overpaying for what you need. Rightsizing is usually a manual process that involves engineering time for looking at a combination of application-level performance metrics like application CPU and Memory consumption and infrastructure-related attributes like what kind of underlying CPU powers an instance type. </p>"},{"location":"aws/services/ec2-pricing/#savings-plans","title":"Savings Plans","text":"<p>EC2 Instances are covered by AWS Savings Plans. Savings Plans are covered more in depth as a general concept here. As it relates to EC2, Savings Plans are preferable as they present the same savings as Reserved Instances but aren't constrained to a single instance type. </p>"},{"location":"aws/services/ec2-pricing/#reserved-instances","title":"Reserved Instances","text":"<p>EC2 Instances are covered by AWS Reserved Instances. Reserved Instances are covered more in depth as a general concept here. As it relates to EC2, Reserved Instances aren't preferred as they present the same savings as Savings Plans but are constrained to a single instance type where as Savings Plans give greater flexibility. </p>"},{"location":"aws/services/ec2-pricing/#generational-upgrades","title":"Generational Upgrades","text":"<p>EC2 instance types are grouped into families (discussed below) with multiple generations. For example a <code>m4.4xlarge</code> is of family type <code>m</code> and generation <code>4</code>. The next generation for the same instance type would be <code>m5.4xlarge</code>. Typically, as cloud infrastructure providers release new families it's cheaper and more performant to run the later generation instance types. Upgrade instances from one generation to another can be a major area of cost savings. Generation upgrades usually result in between 5% and 10% cost savings per generation and varies per family. </p>"},{"location":"aws/services/ec2-pricing/#instance-type-families","title":"Instance Type Families","text":"<p>EC2 Instance Types are organized into \"Families\" and each family can have multiple \"Generations\". By looking at each instance type you can infer its Family and Generation from the instance type name. For example, a <code>c5.4xlarge</code> is the <code>c</code> Family and <code>5th</code> Generation. Below is a table of EC2 Instance Families and simple descriptions:</p> Family Description a ARM Processors c Compute-optimized d Locally attached spinning HDD f Customizable hardware acceleration with FPGAs g Graphics GPU Instances h Large spinning HDD i NVMe SSD-backed storage optimized inf Machine-learning inference mac Apple Mac mini computers m General purpose with balanced CPU, memory and storage p General Purpose GPU r Memory-optimized t Burstable instances x Lowest price-per-GB RAM instances z Highest core frequency <p></p> <p>Contribute</p> <p>Contribute to this page on GitHub or join the <code>#cloud-costs-handbook</code> channel in the Vantage Community Slack.</p>"},{"location":"aws/services/ecr-pricing/","title":"ECR Pricing | Cloud Cost Handbook","text":"<p>Amazon ECR Pricing Page</p>"},{"location":"aws/services/ecr-pricing/#summary","title":"Summary","text":"<p>Amazon Elastic Container Registry (ECR) is a fully managed container registry that allows you to store container images. You can create as many \"Repositories\" as you'd like that are free. As you push container \"Images\" to your repository, you're charged for the storage of these images which can acrue over time. Additionally, ECR charges different data transfer rates for private versus public repositories. </p>"},{"location":"aws/services/ecr-pricing/#pricing-dimensions","title":"Pricing Dimensions","text":"Dimension Description Container Image Storage Amazon ECR charges a rate per month for the amount of storage per GB you store for container images. Data Transfer Amazon ECR charges different rates for data transfer from public and private repositories."},{"location":"aws/services/ecr-pricing/#storage-costs-per-ecr-repository","title":"Storage Costs per ECR Repository","text":"<p>Determining the cost per Container Repository can be a lot of effort, especially if you have a large quantity of images. To calculate the storage cost per container repository:</p> <ul> <li>List all of your container images</li> <li>Collect the image digest from each</li> <li>Determine just the unique digests of the layers in your container repository</li> <li>Get the size of each unique digest.</li> </ul> <p>If you prefer not to do this manually yourself, Vantage will compute the size and corresponding cost of all repositories automatically when you connect an AWS account.</p>"},{"location":"aws/services/ecr-pricing/#lifecycle-policies","title":"Lifecycle Policies","text":"<p>ECR stores every container image you push to a registry by default. Over time, the storage of all of these images can add up. Amazon offers a primitive called a \"Lifecycle Policy\" that allows you to set conditions for having Amazon clean up images on your behalf. There are two types of lifeycle policies:</p> Lifecycle Policy Description imageCountMoreThan ECR allows you to define a certain number of images to retain and anything over that count will be cleaned up. For example if you set a Lifecycle Policy with a imageCountMoreThan value of 10, your most recent 10 images will always be kept. sinceImagePushed ECR allows you to set lifecycle policies with a value of sinceImagePushed which has a value of a certain number of days. So for example if you have a Lifecycle Policy applied with a sinceImagePushed value of 7, ECR will delete images as often as they are older than 7 days. <p>Note: that when you apply a Lifecycle Policy, it is evaluated immediately. So if you have 500 images in a repositority and impose a lifeycle policy of 10 as soon as that policy is applied ECR will delete the 490 oldest images. </p>"},{"location":"aws/services/ecr-pricing/#example-imagecountmorethan-lifeycle-policy","title":"Example <code>imageCountMoreThan</code> Lifeycle Policy","text":"<p>Here's an example of how to impose a Lifeycle Policy via the AWS CLI using the value of imageCountMoreThan: </p> <pre><code>aws ecr put-lifecycle-policy \\\n    --repository-name \"vantage/mcyolo\" \\\n    --lifecycle-policy-text \"file://policy.json\"\n</code></pre> <p>Where the content of the file for policy.json is the following:</p> <pre><code>{\n  \"rules\": [\n     {\n       \"rulePriority\": 1,\n       \"description\": \"Expire images over a count of 10\",\n       \"selection\": {\n         \"tagStatus\": \"untagged\",\n         \"countType\": \"imageCountMoreThan\",\n         \"countNumber\": 10\n       },\n       \"action\": {\n         \"type\": \"expire\"\n       }\n     }\n  ]\n}\n</code></pre>"},{"location":"aws/services/ecr-pricing/#example-sinceimagepushed-lifeycle-policy","title":"Example <code>sinceImagePushed</code> Lifeycle Policy","text":"<p>Here's an example of how to impose a Lifeycle Policy via the AWS CLI using the value of sinceImagePushed: </p> <pre><code>aws ecr put-lifecycle-policy \\\n    --repository-name \"vantage/mcyolo\" \\\n    --lifecycle-policy-text \"file://policy.json\"\n</code></pre> <p>Where the content of the file for policy.json is the following:</p> <pre><code>{\n  \"rules\": [\n     {\n       \"rulePriority\": 1,\n       \"description\": \"Expire images older than 14 days\",\n       \"selection\": {\n         \"tagStatus\": \"untagged\",\n         \"countType\": \"sinceImagePushed\",\n         \"countUnit\": \"days\",\n         \"countNumber\": 14\n       },\n       \"action\": {\n         \"type\": \"expire\"\n       }\n     }\n  ]\n}\n</code></pre> <p></p> <p>Contribute</p> <p>Contribute to this page on GitHub or join the <code>#cloud-costs-handbook</code> channel in the Vantage Community Slack.</p>"},{"location":"aws/services/ecs-and-fargate-pricing/","title":"ECS & Fargate Pricing | Cloud Cost Handbook","text":"<p>ECS Pricing Page Fargate Pricing Page</p>"},{"location":"aws/services/ecs-and-fargate-pricing/#summary","title":"Summary","text":"<p>Elastic Container Service (ECS) allows you to run docker containers through a primitive named a \"Task\". Tasks ultimately run on EC2 instances which are either managed by you (ECS on EC2) or fully managed by AWS (Fargate).</p> <p>There is no additional charge to you when using ECS on self-managed EC2 as you're just paying for EC2 instances that you create and manage. Fargate charges you for the vCPU and Memory for a ECS Task or EKS Pod and you pay a premium for managing the underlying EC2 instances. </p>"},{"location":"aws/services/ecs-and-fargate-pricing/#fargate-pricing-dimensions","title":"Fargate Pricing Dimensions","text":"Dimension Description vCPU Hours When configuring a Fargate Task or EKS Pod you assign a certain amount vCPU and are charged a corresponding per-hour VCPU rate. GB Memory Hours When configuring a Fargate Task or EKS Pod you assign a certain amount GB of Memory and are charged a corresponding per-hour GB of Memory rate."},{"location":"aws/services/ecs-and-fargate-pricing/#fargate-spot","title":"Fargate Spot","text":"<p>Fargate has the ability to run in a Spot capacity which is conceptually the same premise as EC2 Spot - allowing you to run Tasks at up to a 70% discount off the Fargate on-demand price. </p> <p>When the capacity for Fargate Spot is available, you will be able to launch tasks based on your specified request. When AWS needs the capacity back, tasks running on Fargate Spot will be interrupted with two minutes of notification. If the capacity for Fargate Spot stops being available, Fargate will scale down tasks running on Fargate Spot while maintaining any regular tasks you are running.</p>"},{"location":"aws/services/ecs-and-fargate-pricing/#fargate-vs-self-managed-ec2-on-ecs-or-eks","title":"Fargate vs self-managed EC2 on ECS or EKS","text":"<p>Fargate charges a significant premium for managing the underlying nodes. Additionally, Fargate has varying degress of vCPU performance that differ depending on the Task. As a result, Fargate can have pitfalls relative to self-managed ECS or EKS on EC2 beyond just the additional costs. </p> <p>For a more in-depth article for seeing how Fargate is priced relative to self-managed EC2, please read the following blog post for understanding Fargate pricing.</p> <p></p> <p>Contribute</p> <p>Contribute to this page on GitHub or join the <code>#cloud-costs-handbook</code> channel in the Vantage Community Slack.</p>"},{"location":"aws/services/elasticache-pricing/","title":"ElastiCache Pricing | Cloud Cost Handbook","text":"<p>Amazon ElastiCache Pricing Page</p>"},{"location":"aws/services/elasticache-pricing/#summary","title":"Summary","text":"<p>Amazon ElastiCache allows you to set up, run, and scale popular open-source compatible in-memory data stores like Redis or Memcached. ElastiCache ultimately runs atop EC2 instances with pre-configured software and are prefixed with <code>\"cache.\"</code> and are referred to as Nodes.</p>"},{"location":"aws/services/elasticache-pricing/#pricing-dimensions","title":"Pricing Dimensions","text":"Dimension Description Node Usage You are charged for the amount of hours your ElastiCache nodes run."},{"location":"aws/services/elasticache-pricing/#reserved-instances","title":"Reserved Instances","text":"<p>ElastiCache Nodes do have Reserved Instances that can give you significant savings. Reserved Instances are covered as a general concept found here. </p> <p>Typically, as ElastiCache nodes remain on for longer durations and aren't members of auto-scaling groups, they are good candidates for cost savings via Reserved Instances. </p>"},{"location":"aws/services/elasticache-pricing/#savings-plans","title":"Savings Plans","text":"<p>ElastiCache Nodes are not covered under AWS Savings Plans.</p> <p></p> <p>Contribute</p> <p>Contribute to this page on GitHub or join the <code>#cloud-costs-handbook</code> channel in the Vantage Community Slack.</p>"},{"location":"aws/services/elasticsearch-pricing/","title":"Elasticsearch Service Pricing | Cloud Cost Handbook","text":"<p>Amazon Elasticsearch Service Pricing Page</p>"},{"location":"aws/services/elasticsearch-pricing/#summary","title":"Summary","text":"<p>Amazon Elasticsearch Service is a full-managed service which runs ElasticSearch which is used primarily for querying JSOn based search and analytics data. Amazon ElasticSearch Service is billed per instance for the amount of EBS storage attached to the instance and the type of instance which is used to run the service.</p>"},{"location":"aws/services/elasticsearch-pricing/#pricing-dimensions","title":"Pricing Dimensions","text":"Dimension Description Instance Type Usage ElasticSearch instance types are billed at an hourly rate and charged that hourly rate on a per-second basis for your usage. Attached Storage ElasticSearch allows you to attach storage to the instances either as General Purpose Storage or Provisioned IOPS storage. Behind the scenes these are just managed EBS Volumes that ElasticSearch orchestrates on your behalf. However, on your monthly AWS bill these charges will show up under the ElasticSearch service and not under the EBS service. There are also options for high performance local SSD disks for storage optimized instances."},{"location":"aws/services/elasticsearch-pricing/#storage-optimized-instances","title":"Storage Optimized Instances","text":"<p>If better storage performance, above EBS, is needed you can select Storage Optmized instances which include local NVMe SSD disks.</p>"},{"location":"aws/services/elasticsearch-pricing/#reserved-instances","title":"Reserved Instances","text":"<p>As ElasticSearch instances are not covered by AWS Savings Plans, you must rely on procuring Reserved Instances specifically for ElasticSearch. Reserved Instances are covered in depth under General Concepts and we encourage you to read up more on them there for the most up-to-date information.</p> <p></p> <p>Contribute</p> <p>Contribute to this page on GitHub or join the <code>#cloud-costs-handbook</code> channel in the Vantage Community Slack.</p>"},{"location":"aws/services/elb-pricing/","title":"Elastic Load Balancer Pricing | Cloud Cost Handbook","text":"<p>Amazon ELB Pricing Page</p>"},{"location":"aws/services/elb-pricing/#summary","title":"Summary","text":"<p>Amazon Elastic Load Balancer (ELB) is a service which distributes traffic from a single endpoint (public or private) to one or many private resources. Most commonly an Elastic Load Balancer will be exposed to the public internet and will distribute the incoming traffic to several app servers (usually running on EC2 or ECS). Elastic Load Balancers can also be used to distribute private traffic from one service to another. There are different options for the type of ELB and they are priced differently and come with different feature sets.</p>"},{"location":"aws/services/elb-pricing/#pricing-dimensions","title":"Pricing Dimensions","text":"Dimension Description Load Balancer Hours Every type of load balancer has a standard per hour rate and is always billed for a full hour. Load Balancer Data Processed Each type of load balancer has a formula for how the data processed by the load balancer is turned into an additional hourly charged."},{"location":"aws/services/elb-pricing/#application-load-balancer","title":"Application Load Balancer","text":"<p>Application Load Balancers (ALB) are useful for distributing layer 7 (HTTP, HTTPS, gRPC) traffic to application servers or other backends. ALBs have a standard hourly rate per region and a formula for calculating \"LCU\"-hours. The dimensions for calculating LCU are:</p> Dimension Description New Connections A single LCU is 25 new connections per second. Active connections A single LCU is 3,000 active connections per minute. Processed bytes A single LCU is 1 GB per hour for EC2 instances, containers and IP addresses as targets and 0.4 GB per hour for Lambda functions as targets. Rule evaluations A single LCU is 1,000 rule evaluations per second. <p>Whichever of these dimensions produces the highest LCU for an hour is what is used to create the charge for LCU-hour.</p>"},{"location":"aws/services/elb-pricing/#network-load-balancer","title":"Network Load Balancer","text":"<p>Network Load Balacers (NLB) are used for forwarding layer 4 traffic (TCP, UDP, TLS) to any other resoruce with an IP address. NLBs have a standard hourly rate per region and a formula for calculating \"NLCU\"-hours depending on the type of network traffic. The dimensions for calculating NCLU are:</p> Dimension TCP UDP TLS New Connection or Flow 800 400 50 Active Connection or Flow 100,000 50,000 3,000 Processed bytes 1GB 1GB 1GB"},{"location":"aws/services/elb-pricing/#gateway-load-balancer","title":"Gateway Load Balancer","text":"<p>Gateway Load Balancers are used to proxy traffic through third-party virtual appliances which support GENEVE. GLBs have a standard hourly rate per region and a formula for calculating \"GLCU\"-hours. The dimensions for calculating GLCU are:</p> Dimension Description New Connections A single LCU is 600 new connections per second. Active connections A single LCU is 60,000 active connections per minute. Processed bytes A single LCU is 1 GB per hour for EC2 instances, containers and IP addresses as targets and 0.4 GB per hour for Lambda functions as targets."},{"location":"aws/services/elb-pricing/#classic-load-balancer","title":"Classic Load Balancer","text":"<p>Classic load balancers are the original type of load balancer which has since been superceded by ALB and NLB. CLBs support both layer 7 and layer 4 traffic. CLBs have a standard hourly rate per region and a standard per GB rate per region for traffic processed. </p> <p></p> <p>Contribute</p> <p>Contribute to this page on GitHub or join the <code>#cloud-costs-handbook</code> channel in the Vantage Community Slack.</p>"},{"location":"aws/services/emr-pricing/","title":"EMR Pricing | Cloud Cost Handbook","text":"<p>Amazon EMR Pricing Page</p>"},{"location":"aws/services/emr-pricing/#summary","title":"Summary","text":"<p>Amazon Elastic Map Reduce (EMR) is software infrastructure for running map reduce and other big data workloads. It supports open-source frameworks like Apache Spark, projects like Hadoop, and SQL tools like Presto.</p> <p>EMR runs on top of EC2 or EKS instances and also has a serverless option. EMR is available for a wide variety of instances which allows for tight optimization of workloads, for example choosing a compute optimized vs. a memory optimized instance for Spark vs. Hive.</p> <p>To see which EC2 instances are available for EMR, you can add the <code>On EMR</code> and <code>EMR Cost</code> columns on ec2instances.info.</p>"},{"location":"aws/services/emr-pricing/#pricing-dimensions","title":"Pricing Dimensions","text":"<p>EMR is billed differently based on the underlying compute service.</p> Dimension Description Running on EC2 EMR is billed as an additional cost per hour for the instance. For example, a m6g.16xlarge has an EMR cost of ~$0.60 per hour. Running on EKS Running on EKS involves 2 dimensions: vCPUs and GiB of memory, with a minimum charge of 1 minute. Serverless Serverless has Compute, Memory, and Storage dimensions."},{"location":"aws/services/emr-pricing/#emr-optimization","title":"EMR Optimization","text":"<p>Every EMR instance above can also be run as a spot instance, which is likely to be appropriate for \"fault tolerant\" workloads on EMR. As of 2020, it is also possible to use Spot Fleets with the capacity-optimized allocation strategy for running EMR workloads. Lastly, data transfer charges are likely accumulating from the movement of your big data through the EMR system. You can dramatically reduce these charges, or even eliminate them, by connecting to EMR using interface VPC endpoints.</p> <p>Contribute</p> <p>Contribute to this page on GitHub or join the <code>#cloud-costs-handbook</code> channel in the Vantage Community Slack.</p>"},{"location":"aws/services/lambda-pricing/","title":"Lambda Pricing | Cloud Cost Handbook","text":"<p>Lambda Pricing Page</p>"},{"location":"aws/services/lambda-pricing/#summary","title":"Summary","text":"<p>AWS Lambda is a serverless compute service that lets you run code without provisioning or managing servers. You are charged based on the number of requests for your functions and the duration, the time it takes for your code to execute.</p>"},{"location":"aws/services/lambda-pricing/#pricing-dimensions","title":"Pricing Dimensions","text":"Dimension Description Number of requests You are charged $0.20 per 1M requests to your Lambda functions. Duration of request The price for duration depends on the amount of memory you allocate to your function. You can allocate any amount of memory to your function between 128MB and 10,240MB, in 1MB increments."},{"location":"aws/services/lambda-pricing/#lambda-savings-plans","title":"Lambda Savings Plans","text":"<p>There is one additional option for saving on Lambda that is agnostic to whether you're running on x86 or ARM: Savings Plans.</p> <p>Savings Plans are a more flexible way to get discounts on AWS, and they work across EC1, Lambda, Fargate, and SageMaker. No action is required if you already own a Savings Plan. The discount is applied automatically unless you have maxed out that Savings Plan on another service. Savings Planner can help you decide how much of a Savings Plan to buy so you are not over-committed.</p> <p>If you have existing saving plans in use on Lambda and are looking to make the switch to Graviton1, you should also ensure what impact that will have on your coverage as the discount rates for x86 vs Graviton2 are different.</p> <p></p> <p>Contribute</p> <p>Contribute to this page on GitHub or join the <code>#cloud-costs-handbook</code> channel in the Vantage Community Slack.</p>"},{"location":"aws/services/rds-pricing/","title":"RDS Pricing | Cloud Cost Handbook","text":"<p>Amazon RDS Pricing Page</p>"},{"location":"aws/services/rds-pricing/#summary","title":"Summary","text":"<p>Amazon Relational Database Service (RDS) provides you with the ability to create databases running certain software such as MySQL, Postgres, SQL Server and more. RDS instances ultimately are preconfigured EC2 instances running certain managed database software. As a result, you'll see similarities between instance types for RDS and EC2 where RDS instances are prefixed with \"db.\"</p>"},{"location":"aws/services/rds-pricing/#pricing-dimensions","title":"Pricing Dimensions","text":"Dimension Description Instance Type Usage RDS instance types are billed at an hourly rate and charged that hourly rate on a per-second basis for your usage. Database Software As RDS allows you to run different types of database software there are varying costs depending on which database software you choose to use. For example you can run Oracle and MySQL database on the same RDS instance types but they have different pricing as Oracle licensing contributes a higher cost than MySQL. Availability RDS allows you to run RDS instances in either \"Single AZ\" or \"Multi AZ\" deployments. \"Multi AZ\" deployments are more highly available but carry a larger cost. Attached Storage RDS allows you to attach storage to RDS instances either as General Purpose Storage or Provisioned IOPS storage. Behind the scenes these are just managed EBS Volumes that RDS orchestrates on your behalf. However, on your monthly AWS bill these charges will show up under the RDS service and not under the EBS service. Backup Storage You have the ability to turn on backups for your RDS instances and are charged an accompanying storage rate for backups."},{"location":"aws/services/rds-pricing/#reserved-instances","title":"Reserved Instances","text":"<p>As RDS instances are not covered by AWS Savings Plans, you must rely on procuring Reserved Instances specifically for RDS. Reserved Instances are covered in depth under General Concepts and we encourage you to read up more on them there for the most up-to-date information.</p>"},{"location":"aws/services/rds-pricing/#single-vs-multi-availability-zones","title":"Single vs Multi Availability Zones","text":"<p>RDS allows you to deploy instances in either a single availability zone or across multiple availability zones. Shorthand, this is referenced as either \"single-AZ\" or \"multi-AZ\". The benefit of being multi-AZ is that you're provided with enhanced availability and durability for your database as Amazon provisions and maintains a standby in a different availability zone for automatic failover in the event of a scheduled or unplanned outage. </p> <p>From a cost consideration perspective, multi-AZ rates are double what single-AZ rates are for the added durability that you're provided. </p> <p></p> <p>Contribute</p> <p>Contribute to this page on GitHub or join the <code>#cloud-costs-handbook</code> channel in the Vantage Community Slack.</p>"},{"location":"aws/services/route-53-pricing/","title":"Route53 Pricing | Cloud Cost Handbook","text":"<p>Route53 Pricing Page</p>"},{"location":"aws/services/route-53-pricing/#summary","title":"Summary","text":""},{"location":"aws/services/route-53-pricing/#summary_1","title":"Summary","text":"<p>Amazon Route 53 is a Domain Name System (DNS) web service. Typically Route 53 doesn't tend to be a large cost center for the vast majority of companies. </p>"},{"location":"aws/services/route-53-pricing/#pricing-dimensions","title":"Pricing Dimensions","text":"Dimension Description Hosted Zones You are charged either $0.50 or $0.10 per hosted zone per month depending on the number of hosted zones you have. You are charged $0.50 per hosted zone per month for the first 25 hosted zones and $0.10 per hosted zone per month for additional hosted zones. DNS Queries You incur charges for every DNS query answered by the Amazon Route 53 service, except for queries to Alias A records that are mapped to Elastic Load Balancing instances, CloudFront distributions, AWS Elastic Beanstalk environments, API Gateways, VPC endpoints, or Amazon S3 website buckets, which are provided at no additional charge. Registered Domain Names You pay an annual charge for each domain name registered via or transferred into Route 53. <p>Contribute</p> <p>Contribute to this page on GitHub or join the <code>#cloud-costs-handbook</code> channel in the Vantage Community Slack.</p>"},{"location":"aws/services/s3-pricing/","title":"S3 Pricing | Cloud Cost Handbook","text":"<p>Amazon S3 Pricing Page</p>"},{"location":"aws/services/s3-pricing/#summary","title":"Summary","text":"<p>Amazon Simple Storage Service (S3) is an object storage service that allows customers to storage files which are known as \"objects\". Objects are organized into namespaces named \"buckets\" for which there is no additional cost for having. Ultimately you are charged on the dimensions below but are a mix of how much you store with specific storage types, the bandwidth for accessing those files and the requests you make to the S3 service. </p>"},{"location":"aws/services/s3-pricing/#pricing-dimensions","title":"Pricing Dimensions","text":"Dimension Description Object Storage Amount Amazon S3 charges you for how much you store across all objects across all buckets. There is different pricing rates per region on a per-GB basis and as you store more data on S3, you get discounts on a per-GB basis. Object Storage Class Amazon S3 has many different Storage Classes which are discussed below. \"Standard Storage\" is the default storage class but you can get discounts for other tiers. Bandwidth Amazon S3 charges you for the amount of egress you consume for accessing S3 objects. You should keep an eye on how much bandwidth is being consumed especially if files are left open to the public where you can potentially have runaway costs if signifcant usage occurs. Request Metrics Amazon charges you for GET, SELECT, PUT, COPY, POST and LIST requests. Amazon also charges you different rates depending on which of these request types you're using. This is oftentimes an unknown cost that customers occur that you should keep an eye on."},{"location":"aws/services/s3-pricing/#intelligent-tiering","title":"Intelligent Tiering","text":"<p>S3 Intelligent Tiering is an Amazon S3 storage class that automatically will optimize storage costs automatically on behalf of customers. S3 Intelligent Tiering will monitor access patterns of S3 objects on your behalf and shift them between four different storage classes on your behalf to deliver you with savings automatically. </p> <p>Typically customers have files that they store with the storage class of Standard Storage but don't think to ever optimize these costs and overpay for the the amount they're storing in S3. By using Intelligent Tiering, customers can focus on their application development and allow S3 Intelligent Tiering to manage shifting their objects' storage classes on their behalf. </p>"},{"location":"aws/services/s3-pricing/#understanding-storage-classes","title":"Understanding Storage Classes","text":"<p>S3 currently supports 19 different object storage types within an S3 Bucket. Each bucket is capable of holding objects from a single class or multiple classes. A light overview of these storage types are below:</p> Storage Type Description Standard Storage\u200d Standard Storage (StandardStorage) is for general purpose storage for any type of data, typically used for frequently accessed data. Standard Storage is priced on a tiered basis where it gets incrementally cheaper to store data as you store more. Intelligent Tiering - Frequent Access (IntelligentTieringFAStorage) Objects uploaded to S3 Intelligent Tiering are automatically stored in the frequent access tier which has the same rates as Standard Storage. Intelligent Tiering Infrequent Access (IntelligentTieringIAStorage): Objects in Frequent Access that haven't been accessed in 30 consecutive days are moved to this tier in which prices drop significantly. Intelligent Tiering - Archive Access (IntelligentTieringAAStorage) Upon activating the archive access tier for intelligent tiering, S3 will automatically move objects that haven't been accessed for 90 days to archive access where the pricing is the same as Glacier. Intelligent Tiering - Deep Archive Access (IntelligentTieringDAAStorage) Upon activating the deep archive access tier for intelligent tiering, S3 will automatically move objects that haven't been accessed for 180 days to deep archive access. S3 Standard - Infrequent Access (StandardIAStorage) S3 Standard Infrequent Access is for data that is accessed less frequently, but requires rapid access when needed. It offers the high durability, high throughput, and low latency of S3 Standard, with a low per GB storage price and per GB retrieval fee. This combination of low cost and high performance make S3 Standard-IA ideal for long-term storage, backups, and as a data store for disaster recovery files. Standard Infrequenty Access Overhead (StandardIASizeOverhead) There is a minimum billable size of 128KB. For example if you stored an object at 28KB, the StandardIASizeOverhead rate would increase by 128KB-28KB or 100KB and represented by this metric. S3 Standard - Infrequent Access (One Zone) S3 Infrequent Access One Zone is for data that is accessed less frequently, but requires rapid access when needed. Unlike other S3 Storage Classes which store data in a minimum of three Availability Zones, S3 Infrequent Access One Zone stores data in a single AZ and costs 20% less than S3 Standard Infrequent Access. One Zone Size Overhead (OneZoneIASizeOverhead) There is a minimum billable size of 128KB. For example if you stored an object at 28KB, the StandardIASizeOverhead rate would increase by 128KB-28KB or 100KB and represented by this metric. S3 Glacier (GlacierStorage) S3 Glacier is a secure, durable, and low-cost storage class for data archiving. You can reliably store any amount of data at costs that are competitive with or cheaper than on-premises solutions. To keep costs low yet suitable for varying needs, S3 Glacier provides three retrieval options that range from a few minutes to hours. S3 Glacier Overhead (GlacierObjectOverhead) For each object that is stored in S3 Glacier, 40 KB of chargeable overhead is added for metadata S3 Glacier Object Overhead (GlacierObjectOverhead) Amazon S3 Glacier also requires an additional 32KB of data per object for S3 Glacier\u2019s index and metadata. S3 Glacier Deep Archive (DeepArchiveStorage) S3 Glacier Deep Archive is Amazon S3\u2019s lowest-cost storage class and supports long-term retention and digital preservation for data that may be accessed once or twice in a year. It is designed for customers \u2014 particularly those in highly-regulated industries, such as the Financial Services, Healthcare, and Public Sectors \u2014 that retain data sets for 7-10 years or longer to meet regulatory compliance requirements. S3 Glacier Deep Archive can also be used for backup and disaster recovery use cases, and is a cost-effective and easy-to-manage alternative to magnetic tape systems, whether they are on-premises libraries or off-premises services. Deep Archive Object Overhead (DeepArchiveObjectOverhead) For each object that is stored in S3 Glacier, 40 KB of chargeable overhead is added for metadata. Deep Archive S3 Object Overhead (DeepArchiveS3ObjectOverhead) Amazon S3 Deep Archive also requires an additional 32KB of data per object for S3 Deep Archive index and metadata. Deep Archive Staging Storage (DeepArchiveStagingStorage) Staging storage is where the parts of Multipart Upload are staged until the CompleteMultipart request is issued. The parts are staged in S3 standard, and storage is charged at the S3 Standard price. S3 Reduced Redundancy Storage Reduced Redundancy Storage is an Amazon S3 storage option that enables customers to store noncritical, reproducible data at lower levels of redundancy than Amazon S3\u2019s standard storage. It provides a highly available solution for distributing or sharing content that is durably stored elsewhere, or for storing thumbnails, transcoded media, or other processed data that can be easily reproduced. The Reduced Redundancy option stores objects on multiple devices across multiple facilities, providing 400 times the durability of a typical disk drive, but does not replicate objects as many times as standard Amazon S3 storage."},{"location":"aws/services/s3-pricing/#s3-bucket-request-metrics","title":"S3 Bucket Request Metrics","text":"<p>S3 does not have ingress, egress or request metrics turned on by default, leaving many users unsure of what their costs will be until they receive their Monthly AWS Bill. That being said, it's relatively easy to enable these metrics. </p> <p>Below is an example of how to enable these metrics for a S3 Bucket via the AWS CLI. Just be sure to replace <code>YOUR_BUCKET_NAME</code> with your actual bucket name and <code>YOUR_BUCKET_REGION</code> with the appropriate bucket region.</p> <pre><code>aws s3api put-bucket-metrics-configuration \n  --bucket YOUR_BUCKET_NAME\n  --metrics-configuration Id=EntireBucket \n  --id EntireBucket \n  --region YOUR_BUCKET_REGION\n</code></pre> <p>Note: it takes roughly 15 minutes for AWS to begin delivering these metrics after being enabled.</p>"},{"location":"aws/services/s3-pricing/#s3-versus-cloudflare-bandwidth-alliance-partner","title":"S3 Versus Cloudflare Bandwidth Alliance Partner","text":"<p>The Cloudflare Bandwidth Alliance is a group of infrastructure providers that have decided to either completely waive or massively discount egress fees for shared customers. This can be a huge source of savings for customers that have an AWS bill where S3 egress costs make up a large portion of the aforementioned bill.</p> <p>By moving S3 content to Cloudflare's content delivery network (CDN) service in tandem with a Bandwidth Alliance provider, customer can get no-cost content transit from their Cloudflare origin server to Cloudflare servers distributed around the world. This effectively reproduces the cost benefit that users get for pairing CloudFront with an AWS service like S3.1 Utilizing one of Cloudflare's self-serve plans, customer can also cap their cost to deliver content via flat-rate pricing. Further details can be found at in the CloudFront service article of the Cloud Cost Handbook.</p>"},{"location":"aws/services/s3-pricing/#considerations","title":"Considerations","text":"<p>Price is not the only consideration that goes into making a decision about whether to utilize S3 or a competing storage service. Performance, availability, user experience, support and legal compliance are other factors that will factor into the decision to utilize one service over another.</p>"},{"location":"aws/services/s3-pricing/#complexity","title":"Complexity","text":"<p>AWS had made it exceedingly easy for customers to utilize other AWS service in tandem, but there is a non-trivial cost for an organization to decide to split their infrastructure over multiple service providers. Developers will need to learn and understand both systems and when to choose one design pattern over the other. There will be two sets of documentation that will need to be addressed when designing or troubleshooting systems.</p>"},{"location":"aws/services/s3-pricing/#use-cases","title":"Use-cases","text":"<p>The primary use-case in favor of utilizing this cost efficiency architecture strategy is if a user has a large amount of static content that is stored on S3 and being served to end-users via the internet.</p> <p></p> <p>Contribute</p> <p>Contribute to this page on GitHub or join the <code>#cloud-costs-handbook</code> channel in the Vantage Community Slack.</p> <ol> <li> <p>\"If you are using an AWS origin, effective December 1, 2014, data transferred from origin to edge locations (Amazon CloudFront \"origin fetches\") will be free of charge.\" https://aws.amazon.com/cloudfront/pricing/\u00a0\u21a9</p> </li> </ol>"},{"location":"aws/services/vpc-pricing/","title":"VPC Pricing | Cloud Cost Handbook","text":"<p>Amazon VPC Pricing Page</p>"},{"location":"aws/services/vpc-pricing/#summary","title":"Summary","text":"<p>Amazon Virtual Private Cloud (VPC) is a service which allows customers to logically isolate their resources into different networks. Unless explicitly configured every VPC is completely isolated from every other VPC. There is no charge for a VPC in itself, however some optional sub-components of a VPC can incur charges.</p>"},{"location":"aws/services/vpc-pricing/#pricing-dimensions","title":"Pricing Dimensions","text":"Dimension Description NAT Gateway Usage NAT Gateways are billed per hour at a standard rate per region. Each partial hour is billed as a full hour. NAT Gateway Transfer NAT Gateways are billed per GB which is processed by the gateway regaurdless of where the data is being transferred to or from."},{"location":"aws/services/vpc-pricing/#nat-gateway","title":"NAT Gateway","text":"<p>NAT (Network Address Translation) Gateways enable resources running inside of VPCs to connect to services outside of the VPC without needing to have those resources exposed to the public internet. Besides the standard usage and transfer charges on NAT Gateways you will also be charged standard bandwidth transfer charges on top of that depending on where the traffic is going.</p>"},{"location":"aws/services/vpc-pricing/#amazon-vpc-endpoints","title":"Amazon VPC Endpoints","text":"<p>VPC Endpoints allow resources to connect to other AWS services outside of a VPC, such as S3, without the need for a NAT Gateway. This is a good way to prevent NAT Gateway usage and transfer charges.</p> <p></p> <p>Contribute</p> <p>Contribute to this page on GitHub or join the <code>#cloud-costs-handbook</code> channel in the Vantage Community Slack.</p>"},{"location":"aws/services/workspaces-pricing/","title":"WorkSpaces Pricing | Cloud Cost Handbook","text":"<p>Amazon WorkSpaces Pricing Page</p>"},{"location":"aws/services/workspaces-pricing/#summary","title":"Summary","text":"<p>Amazon WorkSpaces is a fully managed, persistent desktop virtualization service. You can use Amazon WorkSpaces to provision either Windows or Linux desktops - each come with their own set of pricing implications discussed below. WorkSpace pricing can either be done in a monthly or hourly fashion. </p>"},{"location":"aws/services/workspaces-pricing/#pricing-dimensions","title":"Pricing Dimensions","text":"Dimension Description Compute Type WorkSpaces offers seven different types of compute types. They are <code>Value</code>, <code>Standard</code>, <code>Performance</code>, <code>Power</code> and <code>PowerPro</code>, <code>Graphics</code>, <code>GraphicsPro</code>. Each of these classes has a different set of underlying resources that contribute to costs differently. The order that these classes are listed in are from cheapest to most expensive. Platform Type Linux or Windows. You are charged an additional amount of money for running on Windows vs Linux. You may also bring your own license for Windows WorkSpaces to reduce Windows licensing costs if you have that available. Running Mode <code>AUTO_STOP</code> or <code>ALWAYS_ON</code>. When you choose <code>AUTO_STOP</code> you are choosing to create a WorkSpace that has a pre-deteremined expiration time in which that WorkSpace will terminate and is billed per hour. When you choose <code>ALWAYS_ON</code> you are charged on a monthly rate basis and the WorkSpace will persist being on until you take action to terminate it. WorkSpace Size Each Compute Type offers four different configurations with different amounts of vCPU and GB of Memory. <code>Graphic</code> and <code>GraphicsPro</code> only offer one size. Depending on the size you choose, you will pay a more expensive rate."},{"location":"aws/services/workspaces-pricing/#monitoring-unused-workspaces","title":"Monitoring Unused WorkSpaces","text":"<p>WorkSpaces have an attribute named <code>last_known_user_connection_timestamp</code> that maintains a timestamp of when was the last time a user has accessed this WorkSpace. You should periodically audit WorkSpaces to ensure that they're being used as otherwise it can be wasteful and a contributor to costs. In the event that this timestamp isn't present, it means that a user has never actually connected to this instance. Additionally, you can look for a certain amount of time that has progressed since a user has accessed it - in the event that a user hasn't accessed a WorkSpace in over a few weeks, it may be a good candidate for clean up and cost savings. </p> <p></p> <p>Contribute</p> <p>Contribute to this page on GitHub or join the <code>#cloud-costs-handbook</code> channel in the Vantage Community Slack.</p>"},{"location":"datadog/committed-use-discounts/","title":"Datadog Committed Use Discounts | Cloud Costs Handbook","text":"<p>Datadog Volume Discount Reference</p> <p>You may contact your Datadog account manager to realize discounts from on-demand spend. Datadog offers monthly minimum usage commitments for at least the following services:</p> <ul> <li>Infrastructure</li> <li>Log Management</li> <li>APM</li> <li>Database Monitoring</li> <li>Cloud Security Management</li> </ul> <p>20-50% savings from your variable usage plans are possible. Note that variable usage plans are still billed annually but a minimum commitment will result in greater savings. Datadog does not publicly share all of the rates for minimum commitments.</p> <p>One example for container monitoring states:</p> <p>Additional containers will be billed at $0.002 per container per hour. In addition, you can purchase prepaid containers at $1 per container per month.</p> <p>In a month that has 744 hours, the \u201con-demand\u201d cost of a container will be $1.488 whereas a committed container would be $1.00 which represents a 32.8% discount. </p>"},{"location":"snowflake/adjustments-for-included-cloud-services/","title":"Snowflake Cloud Services and Adjustments | Cloud Costs Handbook","text":"<p>Snowflake Cloud Services Costs Documentation</p> <p>You may have seen an 'Adjustment for Cloud Services' on a Snowflake bill and wondered why it was negative. Or you may be seeing unexpected charges in the Cloud Services category. Cloud Services are a separate pricing dimension for Snowflake that are reported on but not included in your bill, except in certain cases.</p> <p></p>"},{"location":"snowflake/adjustments-for-included-cloud-services/#cloud-services-adjustment-the-10-threshold","title":"Cloud Services Adjustment: The 10% Threshold","text":"<p>Cloud services are a \"collection of services that coordinate activities across snowflake\". Basically, it's everything that is not involved in running queries or storing data. Most likely, the heaviest cloud service usage will come from:</p> <ul> <li>Metadata management</li> <li>Query parsing and optimization</li> <li>SQL API</li> </ul> <p>Snowflake only starts billing for Cloud Services after they exceed 10% of your compute credits cost. Let's say you spend $100 on Snowflake queries and $9 on cloud services. Your total bill will be $100. But if you spent $19 on cloud services, your bill would be $109. This threshold is recalculated every day for the current day's compute credit usage.</p>"},{"location":"snowflake/adjustments-for-included-cloud-services/#tips-for-reducing-cloud-services-costs","title":"Tips for Reducing Cloud Services Costs","text":"<p>The following common data operations consume cloud services on Snowflake and there are recommended patterns to avoid them.</p> <ul> <li>Full clones. Consider selectively cloning your databases for development, ETL, or backup purposes. Cloning only consumes cloud credits, so if you run a large clone operation on the same day when fewer queries are run, you will pay. Instead, you can clone only the tables you need to stay under the 10% threshold.</li> <li>Fragmented schemas. Snowflake does not recommend using schema design techniques from Hadoop, OLTP, or NoSQL databases where you may have denormalized data spread out amongst multiple schemas. Instead use one schema to minimize metadata lookups.</li> <li>Very complex queries. The query optimization software snowflake runs is broken out into cloud services. So if you write SQL queries that are thousands of lines long, or contain many JOINs or excessive recursion you may find yourself with higher cloud services costs.</li> <li>Excessively frequent queries. Lastly, the SQL API handles the ingestion of each SQL query internally. Requesting this API (running queries) tens of thousands of times per day would start to result in charges.</li> </ul> <p>It's possible that these issues may be caused by third party services running on Snowflake and not your team itself. You can monitor explictly the queries that your company is running by adding query tagging. For more scenarios like the ones above, please contribute to this page or review more Snowflake resources on optimizing Cloud Services costs.</p> <p>Contribute</p> <p>Contribute to this page on GitHub or join the <code>#cloud-costs-handbook</code> channel in the Vantage Community Slack.</p>"},{"location":"tools/cost-reports/","title":"Cost Reports | Cloud Costs Handbook","text":"<p>Cost Reports are multi-dimensional reports for finding and tracking costs. How to use Cost Reports is covered in the Vantage documentation. This page will focus on a compendium of specific types of reports that are helpful for controlling cloud costs.</p>"},{"location":"tools/cost-reports/#report-examples","title":"Report Examples","text":"<p>These use cases have come up repeatedly in the cloud costs community. Contributors are encouraged to add more as they see fit.</p>"},{"location":"tools/cost-reports/#untagged-resources","title":"Untagged Resources","text":"<p>Many organizations use tags to keep track of all their cloud resources. For practioners, keeping the percentage of untagged resources low means greater visibility inside cost tools. Tags must be enabled to be used in Cost Reports.</p>"},{"location":"tools/cost-reports/#showback-report","title":"Showback Report","text":"<p>Shared resources like support or a database cluster make divyying up costs among teams difficult. Use the Cost Allocation tool to create a Showback or Chargeback report for transparent reporting.</p>"},{"location":"tools/cost-reports/#compute-costs-without-data","title":"Compute Costs without Data","text":"<p>Very active data teams generate costs as well as insights. For measuring just the cost to deliver software, exclude these costs from a report.</p>"},{"location":"tools/cost-reports/#just-data-egress","title":"Just Data Egress","text":"<p>Data egress is famously the third cost category of AWS that is very significant for teams, alongside compute and storage. Using subcategories, it is possible to see data egress costs per service.</p>"},{"location":"tools/cost-reports/#redshift-instance-costs","title":"Redshift Instance Costs","text":"<p>EC2 instances power multiple managed services inside AWS. To reveal these, save the Report first then click on the drill-down button on any row. In this example, we are inspecting Redshift instance costs.</p> <p>Contribute</p> <p>Contribute to this page on GitHub or join the <code>#cloud-costs-handbook</code> channel in the Vantage Community Slack.</p>"},{"location":"tools/instances/","title":"Instances Pricing Docmentation | Cloud Cost Handbook","text":"<p>The Instances pricing tool shows current pricing for AWS EC2, RDS, and ElastiCache instances. The tool is completely open source and uses the same Amazon APIs available to everyone. Development for Instances is coordinated through Slack as well as on Github.</p> <p>Instances has a small number of tools for comparing cloud instance pricing and making the best choice for your workload.</p>"},{"location":"tools/instances/#columns-and-filters","title":"Columns and Filters","text":"<p>Nearly every service attribute available for a specific instance is available, although most are hidden by default. You can add more attributes, for example GPUs, in by clicking the <code>Columns</code> dropdown. Other dropdowns allow for selecting the <code>Region</code>, changing the per-unit basis of calculation (e.g. for vCPUs), and changing the term of the <code>Reserved</code> instance purchase.</p> <p>For each column that is shown, it can be further filtered using simple glob matching, and the entire table can be searched using the top right search box.</p>"},{"location":"tools/instances/#regex-support","title":"Regex Support","text":"<p>Each column and the top right search bar support regex expressions. So you can enter an expression like this: <code>[rt][3456].?.larg</code> and the resulting rows will be a mix of t and r instances as shown above.</p>"},{"location":"tools/instances/#comparing-instances","title":"Comparing Instances","text":"<p>By clicking on an individual row in the table, you can select it to be compared with other rows. You can do this while filtering as well. Click <code>Compare Selected</code> and only the selected rows will be shown. The URL is also changed so this specific comparison can be shared with others.</p>"},{"location":"tools/instances/#detail-pages","title":"Detail Pages","text":"<p>For EC2 and RDS, the \"API Name\" column contains clickable links to each instance type. The Detail Page for the instance is essentially a pivot of the main table, with some additional tools to make the information more digestible.</p>"},{"location":"tools/instances/#pricing-widget","title":"Pricing Widget","text":"<p>In the upper left, a pricing widget has selectors for calculating the estimated cost of the instance in different regions, over different amounts of time, or for different software that runs on the instance. When the price is shown as \"N/A\" that indicates that the instance is not available to purchase with the combination of selectors.</p>"},{"location":"tools/instances/#instance-attributes","title":"Instance Attributes","text":"<p>In the middle of each Detail Page are the major categories of attributes and their values. These attributes are all selectable as columns in the main Instances pages. To request more attributes, click \"Open a ticket\" in the bottom right.</p>"},{"location":"tools/instances/#saving-and-clearing-filters","title":"Saving and Clearing Filters","text":"<p>Instances automatically saves the filters and selections that are applied to local storage. This means that when you open a new session you will be greeted with the most recent set of filters and columns. This can be helpful for working on services which mostly use the same types of instances.</p> <p>To reset the table, click <code>Clear Filters</code>.</p>"},{"location":"tools/instances/#export-data","title":"Export Data","text":"<p>The table, with its filters applied, sorted, and with columns shown and hidden, can be exported exactly as a CSV. Data for EC2 is also available for free from the Vantage API.</p> <p>Contribute</p> <p>Contribute to this page on GitHub or join the <code>#cloud-costs-handbook</code> channel in the Vantage Community Slack.</p>"}]}